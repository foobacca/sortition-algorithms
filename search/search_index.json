{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Sortition Algorithms Documentation","text":"<p>Welcome to the documentation for sortition-algorithms - a Python library for democratic lotteries and stratified random selection.</p>"},{"location":"#what-is-sortition","title":"What is Sortition?","text":"<p>Sortition is the random selection of representatives from a larger population, designed to create panels that reflect the demographic composition of the whole group. Unlike simple random sampling, sortition uses stratified random selection to ensure demographic balance while maintaining the randomness essential for fairness.</p> <p>This library provides algorithms for:</p> <ul> <li>Citizens' Assemblies: Representative groups for policy deliberation</li> <li>Deliberative Polls: Research panels reflecting population diversity</li> <li>Jury Selection: Fair selection respecting demographic quotas</li> <li>Participatory Democracy: Community engagement with guaranteed representation</li> </ul>"},{"location":"#quick-start","title":"Quick Start","text":"<pre><code># Install the library\npip install sortition-algorithms\n\n# Basic selection\npython -m sortition_algorithms csv \\\n  --settings config.toml \\\n  --features-csv demographics.csv \\\n  --people-csv candidates.csv \\\n  --selected-csv selected.csv \\\n  --remaining-csv remaining.csv \\\n  --number-wanted 100\n</code></pre>"},{"location":"#documentation-guide","title":"Documentation Guide","text":""},{"location":"#getting-started","title":"Getting Started","text":"<ul> <li>Quick Start Guide - Get up and running in minutes with practical examples</li> <li>Core Concepts - Understand sortition, features, quotas, and address checking</li> <li>Installation &amp; Setup - Install the library and optional dependencies</li> </ul>"},{"location":"#using-the-library","title":"Using the Library","text":"<ul> <li>CLI Usage - Command line interface for common operations</li> <li>Data Adapters - Working with CSV, Google Sheets, and custom data sources</li> <li>API Reference - Extended documentation of key functions and classes</li> <li>Modules - Complete documentation of all functions and classes</li> </ul>"},{"location":"#advanced-topics","title":"Advanced Topics","text":"<ul> <li>Advanced Usage - Performance optimization, complex scenarios, and troubleshooting</li> <li>Algorithm Deep Dive - Understanding maximin, nash, and leximin algorithms</li> <li>Integration Patterns - Web apps, batch processing, and monitoring</li> </ul>"},{"location":"#key-features","title":"Key Features","text":""},{"location":"#stratified-selection","title":"\ud83c\udfaf Stratified Selection","text":"<p>Ensures demographic representativeness while maintaining randomness - no more accidentally all-male or all-young panels.</p>"},{"location":"#household-diversity","title":"\ud83c\udfe0 Household Diversity","text":"<p>Optional address checking prevents multiple selections from the same household, ensuring geographic and social diversity.</p>"},{"location":"#multiple-algorithms","title":"\u2696\ufe0f Multiple Algorithms","text":"<p>Choose from maximin (default), nash, leximin, or legacy algorithms based on your fairness requirements.</p>"},{"location":"#flexible-data-sources","title":"\ud83d\udcca Flexible Data Sources","text":"<p>Works seamlessly with CSV files, Google Sheets, or custom data adapters for databases and APIs.</p>"},{"location":"#full-transparency","title":"\ud83d\udd0d Full Transparency","text":"<p>Detailed reporting shows exactly how quotas were met and provides audit trails for democratic accountability.</p>"},{"location":"#common-use-cases","title":"Common Use Cases","text":""},{"location":"#academic-research","title":"Academic Research","text":"<pre><code>from sortition_algorithms import run_stratification, Settings\n\n# Reproducible results for research\nsettings = Settings(\n    random_number_seed=42,\n    selection_algorithm=\"leximin\"  # Strongest fairness guarantees\n)\nsuccess, panels, msgs = run_stratification(features, people, 150, settings)\n</code></pre>"},{"location":"#citizen-assemblies","title":"Citizen Assemblies","text":"<pre><code># Ensure household diversity for community representation\nsettings = Settings(\n    check_same_address=True,\n    check_same_address_columns=[\"Address\", \"Postcode\"],\n    selection_algorithm=\"maximin\"\n)\n</code></pre>"},{"location":"#large-scale-surveys","title":"Large-Scale Surveys","text":"<pre><code># Batch processing with CLI\npython -m sortition_algorithms csv \\\n  --features-csv national_demographics.csv \\\n  --people-csv voter_registry.csv \\\n  --number-wanted 2000 \\\n  --settings survey_config.toml\n</code></pre>"},{"location":"#algorithm-comparison","title":"Algorithm Comparison","text":"Algorithm Best For Strengths Requirements Maximin General use, citizen assemblies Fair to minorities, intuitive None Nash Large diverse pools Balanced overall representation None Leximin Academic research Strongest fairness guarantees Gurobi license Legacy Historical compatibility Backwards compatible None"},{"location":"#real-world-applications","title":"Real-World Applications","text":""},{"location":"#government-democracy","title":"Government &amp; Democracy","text":"<ul> <li>Ireland's Citizens' Assembly: Used sortition for constitutional reform discussions</li> <li>French Citizens' Convention: 150 citizens selected to address climate change</li> <li>UK Citizens' Assemblies: Local and national policy deliberation</li> </ul>"},{"location":"#research-academia","title":"Research &amp; Academia","text":"<ul> <li>Deliberative Polling: Stanford's Center for Deliberative Democracy</li> <li>Policy Research: Representative samples for social science studies</li> <li>Market Research: Demographically balanced focus groups</li> </ul>"},{"location":"#community-engagement","title":"Community Engagement","text":"<ul> <li>Participatory Budgeting: Community members deciding local spending</li> <li>Planning Consultations: Representative input on development projects</li> <li>Local Government: Advisory panels for municipal decisions</li> </ul>"},{"location":"#support-community","title":"Support &amp; Community","text":""},{"location":"#getting-help","title":"Getting Help","text":"<ul> <li>Troubleshooting Guide - Solutions to common problems</li> <li>GitHub Issues - Report bugs or request features</li> <li>Discussion Forum - Community support and questions</li> </ul>"},{"location":"#contributing","title":"Contributing","text":"<ul> <li>Contributing Guide - How to contribute to the project</li> <li>Development Setup - Set up your development environment</li> </ul>"},{"location":"#research-citations","title":"Research &amp; Citations","text":"<ul> <li>Core Paper - Academic foundation for the algorithms</li> <li>Related Research - Additional academic resources</li> </ul>"},{"location":"#license-usage","title":"License &amp; Usage","text":"<p>This library is open source under the GPL License. You're free to use it for:</p> <ul> <li>\u2705 Academic research and education</li> <li>\u2705 Government and civic applications</li> <li>\u2705 Commercial projects and consulting</li> <li>\u2705 Community organizing and activism</li> </ul> <p>Note: The leximin algorithm requires Gurobi, which has commercial licensing requirements. All other algorithms use open-source solvers.</p>"},{"location":"adapters/","title":"Data Adapters","text":"<p>Data adapters handle loading demographic data and candidate pools from various sources, and exporting selection results back to those sources. The library includes adapters for CSV files and Google Sheets, and you can write custom adapters for other data sources.</p>"},{"location":"adapters/#built-in-adapters","title":"Built-in Adapters","text":""},{"location":"adapters/#csvadapter","title":"CSVAdapter","text":"<p>The most commonly used adapter for working with local CSV files.</p>"},{"location":"adapters/#basic-usage","title":"Basic Usage","text":"<pre><code>from sortition_algorithms import CSVAdapter, Settings\nfrom pathlib import Path\n\nadapter = CSVAdapter()\n\n# Load data\nfeatures, msgs = adapter.load_features_from_file(Path(\"demographics.csv\"))\npeople, msgs = adapter.load_people_from_file(Path(\"candidates.csv\"), Settings(), features)\n\n# Configure output files\nadapter.selected_file = open(\"selected.csv\", \"w\", newline=\"\")\nadapter.remaining_file = open(\"remaining.csv\", \"w\", newline=\"\")\n\n# Export results (after running selection)\nadapter.output_selected_remaining(selected_rows, remaining_rows)\n\n# Clean up\nadapter.selected_file.close()\nadapter.remaining_file.close()\n</code></pre>"},{"location":"adapters/#working-with-string-data","title":"Working with String Data","text":"<p>For data already in memory:</p> <pre><code># Load from string content\nfeatures_csv = \"\"\"feature,value,min,max\nGender,Male,45,55\nGender,Female,45,55\"\"\"\n\npeople_csv = \"\"\"id,Name,Gender\np001,Alice,Female\np002,Bob,Male\"\"\"\n\nfeatures, msgs = adapter.load_features_from_str(features_csv)\npeople, msgs = adapter.load_people_from_str(people_csv, settings, features)\n</code></pre>"},{"location":"adapters/#full-csv-workflow-example","title":"Full CSV Workflow Example","text":"<pre><code>from sortition_algorithms import CSVAdapter, run_stratification, selected_remaining_tables, Settings\nfrom pathlib import Path\nimport csv\n\ndef csv_selection_workflow():\n    # Initialize\n    adapter = CSVAdapter()\n    settings = Settings()\n\n    # Load data\n    features, msgs = adapter.load_features_from_file(Path(\"demographics.csv\"))\n    print(\"\\n\".join(msgs))\n\n    people, msgs = adapter.load_people_from_file(Path(\"candidates.csv\"), settings, features)\n    print(\"\\n\".join(msgs))\n\n    # Run selection\n    success, panels, msgs = run_stratification(features, people, 100, settings)\n\n    if success:\n        # Format results\n        selected_table, remaining_table, _ = selected_remaining_tables(\n            people, panels[0], features, settings\n        )\n\n        # Export results\n        with open(\"selected.csv\", \"w\", newline=\"\") as selected_f, \\\\\n             open(\"remaining.csv\", \"w\", newline=\"\") as remaining_f:\n\n            adapter.selected_file = selected_f\n            adapter.remaining_file = remaining_f\n            adapter.output_selected_remaining(selected_table, remaining_table)\n\n        print(f\"Selected {len(panels[0])} people successfully\")\n    else:\n        print(\"Selection failed\")\n        print(\"\\n\".join(msgs))\n</code></pre>"},{"location":"adapters/#gsheetadapter","title":"GSheetAdapter","text":"<p>For organizations using Google Sheets for data management.</p>"},{"location":"adapters/#setup-requirements","title":"Setup Requirements","text":"<ol> <li>Google Cloud Project: Create a project in Google Cloud Console</li> <li>Enable APIs: Enable Google Sheets API and Google Drive API</li> <li>Service Account: Create service account credentials and download JSON key</li> <li>Share Spreadsheet: Share your spreadsheet with the service account email address</li> </ol>"},{"location":"adapters/#basic-usage_1","title":"Basic Usage","text":"<pre><code>from sortition_algorithms import GSheetAdapter, Settings\nfrom pathlib import Path\n\n# Initialize with credentials\nadapter = GSheetAdapter(\n    auth_json_path=Path(\"/secure/path/credentials.json\"),\n    gen_rem_tab=\"on\"  # Generate remaining tab\n)\n\n# Load data from Google Sheet\nfeatures, msgs = adapter.load_features(\"My Spreadsheet\", \"Demographics\")\nprint(\"\\n\".join(msgs))\n\npeople, msgs = adapter.load_people(\"Candidates\", settings, features)\nprint(\"\\n\".join(msgs))\n\n# Configure output tabs\nadapter.selected_tab_name = \"Selected Panel\"\nadapter.remaining_tab_name = \"Reserve Pool\"\n\n# Export results (after running selection)\nadapter.output_selected_remaining(selected_rows, remaining_rows, settings)\n</code></pre>"},{"location":"adapters/#full-google-sheets-workflow","title":"Full Google Sheets Workflow","text":"<pre><code>from sortition_algorithms import GSheetAdapter, run_stratification, selected_remaining_tables, Settings\nfrom pathlib import Path\n\ndef gsheet_selection_workflow():\n    # Initialize\n    adapter = GSheetAdapter(\n        auth_json_path=Path(\"credentials.json\"),\n        gen_rem_tab=\"on\"\n    )\n    settings = Settings()\n\n    # Load data\n    features, msgs = adapter.load_features(\"Citizen Panel 2024\", \"Demographics\")\n    if features is None:\n        print(\"Failed to load features:\", \"\\n\".join(msgs))\n        return\n\n    people, msgs = adapter.load_people(\"Candidates\", settings, features)\n    if people is None:\n        print(\"Failed to load people:\", \"\\n\".join(msgs))\n        return\n\n    # Run selection\n    success, panels, msgs = run_stratification(features, people, 120, settings)\n\n    if success:\n        # Format results\n        selected_table, remaining_table, _ = selected_remaining_tables(\n            people, panels[0], features, settings\n        )\n\n        # Configure output\n        adapter.selected_tab_name = \"Selected Panel\"\n        adapter.remaining_tab_name = \"Reserve Pool\"\n\n        # Export to Google Sheets\n        dupes = adapter.output_selected_remaining(selected_table, remaining_table, settings)\n\n        print(f\"Selected {len(panels[0])} people successfully\")\n        if dupes:\n            print(f\"Warning: {len(dupes)} people in remaining pool share addresses\")\n    else:\n        print(\"Selection failed:\", \"\\n\".join(msgs))\n</code></pre>"},{"location":"adapters/#google-sheets-data-format","title":"Google Sheets Data Format","text":"<p>Your spreadsheet should be structured as follows:</p> <p>Demographics Tab:</p> feature value min max Gender Male 45 55 Gender Female 45 55 Age 18-30 20 30 <p>Candidates Tab:</p> id Name Email Gender Age Location Address Postcode p001 Alice Smith alice@email.com Female 18-30 Urban 123 Main St 12345 p002 Bob Jones bob@email.com Male 31-50 Rural 456 Oak Ave 67890"},{"location":"adapters/#writing-custom-adapters","title":"Writing Custom Adapters","text":"<p>You can create custom adapters for other data sources like Excel files, SQL databases, or APIs.</p>"},{"location":"adapters/#adapter-interface-pattern","title":"Adapter Interface Pattern","text":"<p>All adapters should implement these core methods:</p> <pre><code>from sortition_algorithms import FeatureCollection, People, Settings\nfrom typing import Protocol\n\nclass SortitionAdapter(Protocol):\n    \"\"\"Protocol defining the adapter interface.\"\"\"\n\n    def load_features(self, source_info: str, **kwargs) -&gt; tuple[FeatureCollection, list[str]]:\n        \"\"\"Load feature definitions from data source.\n\n        Returns:\n            (features, messages) - features object and status messages\n        \"\"\"\n        ...\n\n    def load_people(\n        self,\n        source_info: str,\n        settings: Settings,\n        features: FeatureCollection,\n        **kwargs\n    ) -&gt; tuple[People, list[str]]:\n        \"\"\"Load candidate pool from data source.\n\n        Returns:\n            (people, messages) - people object and status messages\n        \"\"\"\n        ...\n\n    def output_selected_remaining(\n        self,\n        selected_rows: list[list[str]],\n        remaining_rows: list[list[str]],\n        **kwargs\n    ) -&gt; None:\n        \"\"\"Export selection results to data source.\"\"\"\n        ...\n</code></pre>"},{"location":"adapters/#example-excel-adapter","title":"Example: Excel Adapter","text":"<p>Here's a complete example of an Excel adapter using the <code>openpyxl</code> library:</p> <pre><code>from pathlib import Path\nfrom typing import Any\nimport openpyxl\nfrom openpyxl.worksheet.worksheet import Worksheet\n\nfrom sortition_algorithms import FeatureCollection, People, Settings\nfrom sortition_algorithms.features import read_in_features\nfrom sortition_algorithms.people import read_in_people\n\nclass ExcelAdapter:\n    \"\"\"Adapter for Excel files using openpyxl.\"\"\"\n\n    def __init__(self) -&gt; None:\n        self.workbook: openpyxl.Workbook | None = None\n        self.output_file: Path | None = None\n\n    def load_features_from_file(\n        self,\n        excel_file: Path,\n        sheet_name: str = \"Demographics\"\n    ) -&gt; tuple[FeatureCollection, list[str]]:\n        \"\"\"Load features from Excel file.\"\"\"\n        workbook = openpyxl.load_workbook(excel_file)\n\n        if sheet_name not in workbook.sheetnames:\n            return None, [f\"Sheet '{sheet_name}' not found in {excel_file}\"]\n\n        sheet = workbook[sheet_name]\n\n        # Read header row\n        headers = [cell.value for cell in sheet[1]]\n\n        # Read data rows\n        data = []\n        for row in sheet.iter_rows(min_row=2, values_only=True):\n            if any(cell is not None for cell in row):  # Skip empty rows\n                row_dict = {headers[i]: str(row[i]) if row[i] is not None else \"\"\n                           for i in range(len(headers))}\n                data.append(row_dict)\n\n        features, msgs = read_in_features(headers, data)\n        return features, msgs\n\n    def load_people_from_file(\n        self,\n        excel_file: Path,\n        settings: Settings,\n        features: FeatureCollection,\n        sheet_name: str = \"Candidates\"\n    ) -&gt; tuple[People, list[str]]:\n        \"\"\"Load people from Excel file.\"\"\"\n        workbook = openpyxl.load_workbook(excel_file)\n\n        if sheet_name not in workbook.sheetnames:\n            return None, [f\"Sheet '{sheet_name}' not found in {excel_file}\"]\n\n        sheet = workbook[sheet_name]\n\n        # Read header row\n        headers = [cell.value for cell in sheet[1]]\n\n        # Read data rows\n        data = []\n        for row in sheet.iter_rows(min_row=2, values_only=True):\n            if any(cell is not None for cell in row):  # Skip empty rows\n                row_dict = {headers[i]: str(row[i]) if row[i] is not None else \"\"\n                           for i in range(len(headers))}\n                data.append(row_dict)\n\n        people, msgs = read_in_people(headers, data, features, settings)\n        return people, msgs\n\n    def output_selected_remaining(\n        self,\n        selected_rows: list[list[str]],\n        remaining_rows: list[list[str]],\n        output_file: Path,\n        selected_sheet: str = \"Selected\",\n        remaining_sheet: str = \"Remaining\"\n    ) -&gt; None:\n        \"\"\"Export results to Excel file.\"\"\"\n        workbook = openpyxl.Workbook()\n\n        # Remove default sheet\n        workbook.remove(workbook.active)\n\n        # Create selected sheet\n        selected_ws = workbook.create_sheet(selected_sheet)\n        self._write_data_to_sheet(selected_ws, selected_rows)\n\n        # Create remaining sheet\n        remaining_ws = workbook.create_sheet(remaining_sheet)\n        self._write_data_to_sheet(remaining_ws, remaining_rows)\n\n        # Save workbook\n        workbook.save(output_file)\n\n    def _write_data_to_sheet(self, sheet: Worksheet, data: list[list[str]]) -&gt; None:\n        \"\"\"Write data rows to worksheet.\"\"\"\n        for row_idx, row_data in enumerate(data, 1):\n            for col_idx, cell_value in enumerate(row_data, 1):\n                sheet.cell(row=row_idx, column=col_idx, value=cell_value)\n\n        # Style header row\n        if data:\n            for cell in sheet[1]:\n                cell.font = openpyxl.styles.Font(bold=True)\n                cell.fill = openpyxl.styles.PatternFill(\"solid\", fgColor=\"CCCCCC\")\n\n# Usage example\ndef excel_workflow():\n    adapter = ExcelAdapter()\n    settings = Settings()\n\n    # Load data\n    features, msgs = adapter.load_features_from_file(\n        Path(\"selection_data.xlsx\"), \"Demographics\"\n    )\n    people, msgs = adapter.load_people_from_file(\n        Path(\"selection_data.xlsx\"), settings, features, \"Candidates\"\n    )\n\n    # Run selection (assuming you have the selection logic)\n    # success, panels, msgs = run_stratification(...)\n\n    # Export results\n    # adapter.output_selected_remaining(\n    #     selected_table, remaining_table, Path(\"results.xlsx\")\n    # )\n</code></pre>"},{"location":"adapters/#example-sql-database-adapter","title":"Example: SQL Database Adapter","text":"<p>For larger datasets stored in databases:</p> <pre><code>import sqlite3\nfrom pathlib import Path\nfrom typing import Any\n\nfrom sortition_algorithms import FeatureCollection, People, Settings\nfrom sortition_algorithms.features import read_in_features\nfrom sortition_algorithms.people import read_in_people\n\nclass SQLiteAdapter:\n    \"\"\"Adapter for SQLite databases.\"\"\"\n\n    def __init__(self, db_path: Path) -&gt; None:\n        self.db_path = db_path\n\n    def load_features_from_db(\n        self,\n        table_name: str = \"features\"\n    ) -&gt; tuple[FeatureCollection, list[str]]:\n        \"\"\"Load features from database table.\"\"\"\n        conn = sqlite3.connect(self.db_path)\n        conn.row_factory = sqlite3.Row\n\n        try:\n            cursor = conn.execute(f\"SELECT * FROM {table_name}\")\n            rows = cursor.fetchall()\n\n            if not rows:\n                return None, [f\"No data found in table {table_name}\"]\n\n            # Convert to format expected by read_in_features\n            headers = list(rows[0].keys())\n            data = [{col: str(row[col]) for col in headers} for row in rows]\n\n            features, msgs = read_in_features(headers, data)\n            return features, msgs\n\n        finally:\n            conn.close()\n\n    def load_people_from_db(\n        self,\n        settings: Settings,\n        features: FeatureCollection,\n        table_name: str = \"candidates\",\n        where_clause: str = \"\"\n    ) -&gt; tuple[People, list[str]]:\n        \"\"\"Load people from database table.\"\"\"\n        conn = sqlite3.connect(self.db_path)\n        conn.row_factory = sqlite3.Row\n\n        try:\n            query = f\"SELECT * FROM {table_name}\"\n            if where_clause:\n                query += f\" WHERE {where_clause}\"\n\n            cursor = conn.execute(query)\n            rows = cursor.fetchall()\n\n            if not rows:\n                return None, [f\"No candidates found in table {table_name}\"]\n\n            # Convert to format expected by read_in_people\n            headers = list(rows[0].keys())\n            data = [{col: str(row[col]) for col in headers} for row in rows]\n\n            people, msgs = read_in_people(headers, data, features, settings)\n            return people, msgs\n\n        finally:\n            conn.close()\n\n    def output_selected_remaining(\n        self,\n        selected_rows: list[list[str]],\n        remaining_rows: list[list[str]],\n        selected_table: str = \"selected_panel\",\n        remaining_table: str = \"remaining_pool\"\n    ) -&gt; None:\n        \"\"\"Export results to database tables.\"\"\"\n        conn = sqlite3.connect(self.db_path)\n\n        try:\n            # Create tables if they don't exist\n            if selected_rows:\n                headers = selected_rows[0]\n                self._create_table_from_headers(conn, selected_table, headers)\n                self._insert_data(conn, selected_table, headers, selected_rows[1:])\n\n            if remaining_rows:\n                headers = remaining_rows[0]\n                self._create_table_from_headers(conn, remaining_table, headers)\n                self._insert_data(conn, remaining_table, headers, remaining_rows[1:])\n\n            conn.commit()\n\n        finally:\n            conn.close()\n\n    def _create_table_from_headers(\n        self,\n        conn: sqlite3.Connection,\n        table_name: str,\n        headers: list[str]\n    ) -&gt; None:\n        \"\"\"Create table with columns based on headers.\"\"\"\n        conn.execute(f\"DROP TABLE IF EXISTS {table_name}\")\n\n        columns = \", \".join(f\"{header} TEXT\" for header in headers)\n        conn.execute(f\"CREATE TABLE {table_name} ({columns})\")\n\n    def _insert_data(\n        self,\n        conn: sqlite3.Connection,\n        table_name: str,\n        headers: list[str],\n        data_rows: list[list[str]]\n    ) -&gt; None:\n        \"\"\"Insert data rows into table.\"\"\"\n        placeholders = \", \".join(\"?\" * len(headers))\n        query = f\"INSERT INTO {table_name} VALUES ({placeholders})\"\n\n        conn.executemany(query, data_rows)\n\n# Usage example\ndef sqlite_workflow():\n    adapter = SQLiteAdapter(Path(\"selection.db\"))\n    settings = Settings()\n\n    # Load data\n    features, msgs = adapter.load_features_from_db(\"demographics\")\n    people, msgs = adapter.load_people_from_db(\n        settings, features, \"candidates\", \"status = 'eligible'\"\n    )\n\n    # Export results\n    # adapter.output_selected_remaining(\n    #     selected_table, remaining_table, \"panel_2024\", \"reserves_2024\"\n    # )\n</code></pre>"},{"location":"adapters/#advanced-adapter-patterns","title":"Advanced Adapter Patterns","text":""},{"location":"adapters/#caching-adapter","title":"Caching Adapter","text":"<p>For expensive data sources, implement caching:</p> <pre><code>import pickle\nfrom pathlib import Path\nfrom datetime import datetime, timedelta\n\nclass CachingAdapter:\n    \"\"\"Wrapper that adds caching to any adapter.\"\"\"\n\n    def __init__(self, base_adapter: Any, cache_dir: Path, cache_ttl_hours: int = 24):\n        self.base_adapter = base_adapter\n        self.cache_dir = cache_dir\n        self.cache_ttl = timedelta(hours=cache_ttl_hours)\n        self.cache_dir.mkdir(exist_ok=True)\n\n    def load_features(self, *args, **kwargs) -&gt; tuple[FeatureCollection, list[str]]:\n        cache_key = f\"features_{hash(str(args) + str(kwargs))}.pickle\"\n        cache_file = self.cache_dir / cache_key\n\n        # Check cache\n        if cache_file.exists():\n            cache_time = datetime.fromtimestamp(cache_file.stat().st_mtime)\n            if datetime.now() - cache_time &lt; self.cache_ttl:\n                with open(cache_file, \"rb\") as f:\n                    return pickle.load(f)\n\n        # Load fresh data\n        result = self.base_adapter.load_features(*args, **kwargs)\n\n        # Cache result\n        with open(cache_file, \"wb\") as f:\n            pickle.dump(result, f)\n\n        return result\n</code></pre>"},{"location":"adapters/#validation-adapter","title":"Validation Adapter","text":"<p>Add data validation to any adapter:</p> <pre><code>class ValidatingAdapter:\n    \"\"\"Wrapper that adds validation to any adapter.\"\"\"\n\n    def __init__(self, base_adapter: Any):\n        self.base_adapter = base_adapter\n\n    def load_people(self, *args, **kwargs) -&gt; tuple[People, list[str]]:\n        people, msgs = self.base_adapter.load_people(*args, **kwargs)\n\n        # Add validation\n        validation_msgs = self._validate_people(people)\n        msgs.extend(validation_msgs)\n\n        return people, msgs\n\n    def _validate_people(self, people: People) -&gt; list[str]:\n        \"\"\"Validate people data quality.\"\"\"\n        msgs = []\n\n        # Check for duplicate IDs\n        seen_ids = set()\n        for person_id in people:\n            if person_id in seen_ids:\n                msgs.append(f\"Duplicate ID found: {person_id}\")\n            seen_ids.add(person_id)\n\n        # Check for missing required fields\n        required_fields = [\"Name\", \"Email\"]\n        for person_id in people:\n            person_data = people.get_person_dict(person_id)\n            for field in required_fields:\n                if not person_data.get(field):\n                    msgs.append(f\"Missing {field} for person {person_id}\")\n\n        return msgs\n</code></pre>"},{"location":"adapters/#best-practices","title":"Best Practices","text":""},{"location":"adapters/#error-handling","title":"Error Handling","text":"<p>Always provide detailed error messages:</p> <pre><code>def load_features_from_api(self, api_url: str) -&gt; tuple[FeatureCollection | None, list[str]]:\n    try:\n        response = requests.get(api_url, timeout=30)\n        response.raise_for_status()\n\n        data = response.json()\n        features, msgs = read_in_features(data[\"headers\"], data[\"rows\"])\n        return features, msgs\n\n    except requests.RequestException as e:\n        return None, [f\"Failed to load from API: {e}\"]\n    except KeyError as e:\n        return None, [f\"Invalid API response format: missing {e}\"]\n    except Exception as e:\n        return None, [f\"Unexpected error: {e}\"]\n</code></pre>"},{"location":"adapters/#configuration","title":"Configuration","text":"<p>Make adapters configurable:</p> <pre><code>class ConfigurableAdapter:\n    def __init__(self, config: dict):\n        self.config = config\n        self.timeout = config.get(\"timeout\", 30)\n        self.retry_count = config.get(\"retries\", 3)\n        self.batch_size = config.get(\"batch_size\", 1000)\n</code></pre>"},{"location":"adapters/#testing-custom-adapters","title":"Testing Custom Adapters","text":"<p>Test your adapters with known data:</p> <pre><code>def test_excel_adapter():\n    adapter = ExcelAdapter()\n\n    # Test with known data\n    features, msgs = adapter.load_features_from_file(\n        Path(\"test_data.xlsx\"), \"TestFeatures\"\n    )\n\n    assert features is not None\n    assert len(features.feature_names) &gt; 0\n    assert \"Gender\" in features.feature_names\n</code></pre>"},{"location":"adapters/#resource-cleanup","title":"Resource Cleanup","text":"<p>Ensure proper resource cleanup:</p> <pre><code>class DatabaseAdapter:\n    def __enter__(self):\n        self.connection = connect_to_database()\n        return self\n\n    def __exit__(self, exc_type, exc_val, exc_tb):\n        if hasattr(self, 'connection'):\n            self.connection.close()\n\n# Usage\nwith DatabaseAdapter() as adapter:\n    features, msgs = adapter.load_features(...)\n    # Connection automatically closed\n</code></pre>"},{"location":"adapters/#integration-examples","title":"Integration Examples","text":""},{"location":"adapters/#pandas-integration","title":"Pandas Integration","text":"<pre><code>import pandas as pd\n\nclass PandasAdapter:\n    \"\"\"Adapter for pandas DataFrames.\"\"\"\n\n    def load_features_from_dataframe(\n        self, df: pd.DataFrame\n    ) -&gt; tuple[FeatureCollection, list[str]]:\n        headers = df.columns.tolist()\n        data = df.to_dict('records')\n        # Convert all values to strings\n        data = [{k: str(v) for k, v in row.items()} for row in data]\n\n        features, msgs = read_in_features(headers, data)\n        return features, msgs\n</code></pre>"},{"location":"adapters/#aws-s3-integration","title":"AWS S3 Integration","text":"<pre><code>import boto3\nimport csv\nfrom io import StringIO\n\nclass S3Adapter:\n    \"\"\"Adapter for files stored in AWS S3.\"\"\"\n\n    def __init__(self, bucket_name: str):\n        self.bucket_name = bucket_name\n        self.s3_client = boto3.client('s3')\n\n    def load_features_from_s3(\n        self, key: str\n    ) -&gt; tuple[FeatureCollection, list[str]]:\n        try:\n            response = self.s3_client.get_object(Bucket=self.bucket_name, Key=key)\n            content = response['Body'].read().decode('utf-8')\n\n            # Parse CSV content\n            csv_file = StringIO(content)\n            reader = csv.DictReader(csv_file)\n\n            headers = reader.fieldnames\n            data = list(reader)\n\n            features, msgs = read_in_features(headers, data)\n            return features, msgs\n\n        except Exception as e:\n            return None, [f\"Failed to load from S3: {e}\"]\n</code></pre>"},{"location":"adapters/#next-steps","title":"Next Steps","text":"<ul> <li>Core Concepts - Understand sortition fundamentals</li> <li>API Reference - Complete function documentation</li> <li>CLI Usage - Command line interface</li> <li>Advanced Usage - Complex scenarios and optimization</li> </ul>"},{"location":"advanced/","title":"Advanced Usage","text":"<p>This guide covers complex scenarios, optimization techniques, troubleshooting strategies, and advanced usage patterns for the sortition algorithms library.</p>"},{"location":"advanced/#algorithm-deep-dive","title":"Algorithm Deep Dive","text":""},{"location":"advanced/#understanding-selection-algorithms","title":"Understanding Selection Algorithms","text":"<p>Each algorithm optimizes for different fairness criteria:</p>"},{"location":"advanced/#maximin-algorithm-default","title":"Maximin Algorithm (Default)","text":"<p>Objective: Maximize the minimum selection probability across all groups.</p> <pre><code>settings = Settings(selection_algorithm=\"maximin\")\n</code></pre> <p>When to use:</p> <ul> <li>Default choice for most applications</li> <li>Ensures no group is severely underrepresented</li> <li>Good for citizen assemblies and deliberative panels</li> </ul> <p>Trade-offs:</p> <ul> <li>May not optimize overall fairness</li> <li>Can be conservative in selection choices</li> </ul> <p>Example scenario: A panel where ensuring minimum representation for small minorities is crucial.</p>"},{"location":"advanced/#nash-algorithm","title":"Nash Algorithm","text":"<p>Objective: Maximize the product of all selection probabilities.</p> <pre><code>settings = Settings(selection_algorithm=\"nash\")\n</code></pre> <p>When to use:</p> <ul> <li>Large, diverse candidate pools</li> <li>When you want balanced representation across all groups</li> <li>Academic research requiring mathematical optimality</li> </ul> <p>Trade-offs:</p> <ul> <li>More complex optimization</li> <li>May be harder to explain to stakeholders</li> </ul> <p>Example scenario: Research study requiring theoretically optimal fairness across all demographic groups.</p>"},{"location":"advanced/#leximin-algorithm","title":"Leximin Algorithm","text":"<p>Objective: Lexicographic maximin optimization (requires Gurobi license).</p> <pre><code>settings = Settings(selection_algorithm=\"leximin\")\n</code></pre> <p>When to use:</p> <ul> <li>Academic research requiring strongest fairness guarantees</li> <li>When you have access to Gurobi (commercial/academic license)</li> <li>High-stakes selections where maximum fairness is essential</li> </ul> <p>Trade-offs:</p> <ul> <li>Requires commercial solver (Gurobi)</li> <li>More computationally intensive</li> <li>May be overkill for routine selections</li> </ul> <p>Example scenario: Government-sponsored citizen assembly where mathematical proof of fairness is required.</p>"},{"location":"advanced/#legacy-algorithm","title":"Legacy Algorithm","text":"<p>Objective: Backwards compatibility with earlier implementations.</p> <pre><code>settings = Settings(selection_algorithm=\"legacy\")\n</code></pre> <p>When to use:</p> <ul> <li>Reproducing historical selections</li> <li>Comparison studies</li> <li>Specific compatibility requirements</li> </ul> <p>Trade-offs:</p> <ul> <li>Less sophisticated than modern algorithms</li> <li>May not provide optimal fairness</li> </ul>"},{"location":"advanced/#algorithm-performance-comparison","title":"Algorithm Performance Comparison","text":"<pre><code>def compare_algorithms():\n    algorithms = [\"maximin\", \"nash\", \"leximin\"]\n    results = {}\n\n    for algorithm in algorithms:\n        settings = Settings(\n            selection_algorithm=algorithm,\n            random_number_seed=42  # For fair comparison\n        )\n\n        start_time = time.time()\n        success, panels, msgs = run_stratification(\n            features, people, 100, settings\n        )\n        end_time = time.time()\n\n        results[algorithm] = {\n            \"success\": success,\n            \"runtime\": end_time - start_time,\n            \"panel_size\": len(panels[0]) if success else 0,\n            \"messages\": len(msgs)\n        }\n\n    return results\n</code></pre>"},{"location":"advanced/#complex-scenarios","title":"Complex Scenarios","text":""},{"location":"advanced/#multiple-selection-rounds","title":"Multiple Selection Rounds","text":"<p>For applications requiring multiple panels:</p> <pre><code>def multiple_panel_selection():\n    settings = Settings(random_number_seed=None)  # Different each time\n    all_panels = []\n    remaining_people = deepcopy(original_people)\n\n    for round_num in range(5):  # 5 panels of 50 each\n        success, panels, msgs = run_stratification(\n            features, remaining_people, 50, settings\n        )\n\n        if success:\n            selected_panel = panels[0]\n            all_panels.append(selected_panel)\n\n            # Remove selected people from pool\n            for person_id in selected_panel:\n                remaining_people.remove(person_id)\n\n            print(f\"Round {round_num + 1}: Selected {len(selected_panel)} people\")\n            print(f\"Remaining pool: {len(remaining_people)} people\")\n        else:\n            print(f\"Round {round_num + 1} failed: {msgs}\")\n            break\n\n    return all_panels\n</code></pre>"},{"location":"advanced/#weighted-selection","title":"Weighted Selection","text":"<p>For scenarios where some demographic groups need stronger representation:</p> <pre><code>def create_weighted_features():\n    \"\"\"Create features with weighted quotas for underrepresented groups.\"\"\"\n\n    # Standard proportional representation\n    base_features = [\n        (\"Gender\", \"Male\", 45, 55),\n        (\"Gender\", \"Female\", 45, 55),\n        (\"Age\", \"18-30\", 20, 30),\n        (\"Age\", \"31-50\", 35, 45),\n        (\"Age\", \"51+\", 25, 35),\n    ]\n\n    # Weighted to ensure representation of underrepresented groups\n    weighted_features = [\n        (\"Gender\", \"Male\", 40, 50),       # Slightly reduce majority\n        (\"Gender\", \"Female\", 45, 55),     # Maintain strong representation\n        (\"Gender\", \"Non-binary\", 5, 10),  # Ensure inclusion\n        (\"Age\", \"18-30\", 25, 35),         # Boost young representation\n        (\"Age\", \"31-50\", 35, 45),\n        (\"Age\", \"51+\", 20, 30),\n    ]\n\n    return create_features_from_list(weighted_features)\n\ndef create_features_from_list(feature_list):\n    \"\"\"Helper to create FeatureCollection from tuples.\"\"\"\n    import csv\n    from io import StringIO\n\n    # Convert to CSV format\n    csv_content = \"feature,value,min,max\\n\"\n    for feature, value, min_val, max_val in feature_list:\n        csv_content += f\"{feature},{value},{min_val},{max_val}\\n\"\n\n    # Use CSV adapter to create FeatureCollection\n    adapter = CSVAdapter()\n    features, msgs = adapter.load_features_from_str(csv_content)\n    return features\n</code></pre>"},{"location":"advanced/#dynamic-quota-adjustment","title":"Dynamic Quota Adjustment","text":"<p>Automatically adjust quotas based on available candidates:</p> <pre><code>def adjust_quotas_for_availability(features: FeatureCollection, people: People) -&gt; FeatureCollection:\n    \"\"\"Adjust quotas based on actual candidate availability.\"\"\"\n\n    # Count available people in each category\n    category_counts = {}\n    for person_id in people:\n        person_data = people.get_person_dict(person_id)\n\n        for feature_name in features.feature_names:\n            feature_value = person_data.get(feature_name, \"Unknown\")\n            key = (feature_name, feature_value)\n            category_counts[key] = category_counts.get(key, 0) + 1\n\n    # Calculate proportional quotas\n    total_people = len(people)\n    adjusted_features = []\n\n    for feature_name, value_name, value_counts in features.feature_values_counts():\n        available = category_counts.get((feature_name, value_name), 0)\n\n        if available == 0:\n            # No candidates available - set quotas to 0\n            min_quota = max_quota = 0\n        else:\n            # Calculate proportional representation with some flexibility\n            proportion = available / total_people\n            min_quota = max(0, int(proportion * 100) - 5)  # Allow 5% flexibility\n            max_quota = min(available, int(proportion * 100) + 5)\n\n        adjusted_features.append((feature_name, value_name, min_quota, max_quota))\n\n    return create_features_from_list(adjusted_features)\n</code></pre>"},{"location":"advanced/#hierarchical-quotas","title":"Hierarchical Quotas","text":"<p>For complex quota relationships:</p> <pre><code>def hierarchical_quota_validation(features: FeatureCollection, panel_size: int) -&gt; list[str]:\n    \"\"\"Validate hierarchical quota constraints.\"\"\"\n    warnings = []\n\n    # Example: Age + Education constraints\n    # Ensure university graduates are distributed across age groups\n\n    age_university_constraints = {\n        (\"Age\", \"18-30\", \"Education\", \"University\"): (5, 15),  # 5-15 young graduates\n        (\"Age\", \"31-50\", \"Education\", \"University\"): (10, 20), # 10-20 middle-age graduates\n        (\"Age\", \"51+\", \"Education\", \"University\"): (5, 15),    # 5-15 older graduates\n    }\n\n    for (age_feature, age_value, edu_feature, edu_value), (min_q, max_q) in age_university_constraints.items():\n        # This is conceptual - actual implementation would need\n        # custom constraint checking logic\n        warnings.append(f\"Hierarchical constraint: {age_value} {edu_value} should be {min_q}-{max_q}\")\n\n    return warnings\n</code></pre>"},{"location":"advanced/#performance-optimization","title":"Performance Optimization","text":""},{"location":"advanced/#large-dataset-handling","title":"Large Dataset Handling","text":"<p>For pools with hundreds of thousands of candidates:</p> <pre><code>def optimize_for_large_datasets():\n    settings = Settings(\n        # Reduce retry attempts for speed\n        max_attempts=3,\n\n        # Use faster algorithm\n        selection_algorithm=\"maximin\",\n\n        # Minimize address checking overhead if not needed\n        check_same_address=False\n    )\n\n    return settings\n\ndef batch_process_candidates(people_file: Path, batch_size: int = 10000):\n    \"\"\"Process large candidate files in batches.\"\"\"\n\n    # Read file in chunks\n    import pandas as pd\n\n    chunk_iter = pd.read_csv(people_file, chunksize=batch_size)\n\n    all_people = []\n    for chunk in chunk_iter:\n        # Process each chunk\n        chunk_dict = chunk.to_dict('records')\n        all_people.extend(chunk_dict)\n\n        # Optional: provide progress feedback\n        print(f\"Processed {len(all_people)} candidates...\")\n\n    return all_people\n</code></pre>"},{"location":"advanced/#memory-management","title":"Memory Management","text":"<p>For memory-constrained environments:</p> <pre><code>def memory_efficient_selection():\n    \"\"\"Demonstrate memory-efficient patterns.\"\"\"\n\n    # Use generators instead of loading all data at once\n    def load_people_generator(file_path: Path):\n        with open(file_path, 'r') as f:\n            reader = csv.DictReader(f)\n            for row in reader:\n                yield row\n\n    # Process in smaller batches\n    def process_in_batches(data_generator, batch_size: int = 1000):\n        batch = []\n        for item in data_generator:\n            batch.append(item)\n            if len(batch) &gt;= batch_size:\n                yield batch\n                batch = []\n        if batch:\n            yield batch\n\n    # Clean up intermediate objects\n    import gc\n\n    def cleanup_after_selection():\n        gc.collect()  # Force garbage collection\n</code></pre>"},{"location":"advanced/#parallel-processing","title":"Parallel Processing","text":"<p>For multiple independent selections:</p> <pre><code>import concurrent.futures\nfrom multiprocessing import Pool\n\ndef parallel_selections(features, people, panel_sizes: list[int]):\n    \"\"\"Run multiple selections in parallel.\"\"\"\n\n    def run_single_selection(panel_size):\n        settings = Settings(random_number_seed=None)  # Different seed each time\n        return run_stratification(features, people, panel_size, settings)\n\n    # Use process pool for CPU-bound work\n    with Pool() as pool:\n        results = pool.map(run_single_selection, panel_sizes)\n\n    return results\n\ndef concurrent_algorithm_comparison(features, people, panel_size: int):\n    \"\"\"Compare algorithms concurrently.\"\"\"\n\n    algorithms = [\"maximin\", \"nash\"]\n\n    def test_algorithm(algorithm):\n        settings = Settings(\n            selection_algorithm=algorithm,\n            random_number_seed=42  # Same seed for fair comparison\n        )\n        return run_stratification(features, people, panel_size, settings)\n\n    with concurrent.futures.ThreadPoolExecutor() as executor:\n        futures = {executor.submit(test_algorithm, alg): alg for alg in algorithms}\n        results = {}\n\n        for future in concurrent.futures.as_completed(futures):\n            algorithm = futures[future]\n            results[algorithm] = future.result()\n\n    return results\n</code></pre>"},{"location":"advanced/#troubleshooting-guide","title":"Troubleshooting Guide","text":""},{"location":"advanced/#common-error-patterns","title":"Common Error Patterns","text":""},{"location":"advanced/#infeasible-quotas","title":"Infeasible Quotas","text":"<p>Symptoms: <code>InfeasibleQuotasError</code> exception</p> <p>Diagnosis:</p> <pre><code>def diagnose_quota_feasibility(features: FeatureCollection, panel_size: int):\n    \"\"\"Analyze why quotas might be infeasible.\"\"\"\n\n    issues = []\n\n    # Check if minimum quotas exceed panel size\n    total_minimums = sum(\n        value_counts.min\n        for _, _, value_counts in features.feature_values_counts()\n    )\n\n    if total_minimums &gt; panel_size:\n        issues.append(f\"Sum of minimums ({total_minimums}) exceeds panel size ({panel_size})\")\n\n    # Check for impossible individual quotas\n    for feature_name, value_name, value_counts in features.feature_values_counts():\n        if value_counts.min &gt; panel_size:\n            issues.append(f\"{feature_name}:{value_name} minimum ({value_counts.min}) exceeds panel size\")\n\n        if value_counts.max &lt; value_counts.min:\n            issues.append(f\"{feature_name}:{value_name} max ({value_counts.max}) &lt; min ({value_counts.min})\")\n\n    return issues\n\ndef suggest_quota_fixes(features: FeatureCollection, people: People, panel_size: int):\n    \"\"\"Suggest quota adjustments to make selection feasible.\"\"\"\n\n    suggestions = []\n\n    # Count available people per category\n    availability = {}\n    for person_id in people:\n        person_data = people.get_person_dict(person_id)\n        for feature_name in features.feature_names:\n            value = person_data.get(feature_name, \"Unknown\")\n            key = (feature_name, value)\n            availability[key] = availability.get(key, 0) + 1\n\n    # Suggest adjustments\n    for feature_name, value_name, value_counts in features.feature_values_counts():\n        available = availability.get((feature_name, value_name), 0)\n\n        if value_counts.min &gt; available:\n            suggestions.append(\n                f\"Reduce {feature_name}:{value_name} minimum from {value_counts.min} to {available} \"\n                f\"(only {available} candidates available)\"\n            )\n\n    return suggestions\n</code></pre> <p>Solutions:</p> <ol> <li>Reduce minimum quotas: Lower the minimum requirements</li> <li>Increase maximum quotas: Allow more flexibility</li> <li>Expand candidate pool: Recruit more candidates in underrepresented categories</li> <li>Adjust panel size: Sometimes a smaller or larger panel works better</li> </ol>"},{"location":"advanced/#data-quality-issues","title":"Data Quality Issues","text":"<p>Symptoms: Unexpected selection results, warnings about data inconsistencies</p> <p>Diagnosis:</p> <pre><code>def audit_data_quality(people: People, features: FeatureCollection):\n    \"\"\"Comprehensive data quality audit.\"\"\"\n\n    issues = []\n\n    # Check for missing demographic data\n    required_features = features.feature_names\n    for person_id in people:\n        person_data = people.get_person_dict(person_id)\n\n        for feature in required_features:\n            if feature not in person_data or not person_data[feature].strip():\n                issues.append(f\"Person {person_id} missing {feature}\")\n\n    # Check for unexpected feature values\n    expected_values = {}\n    for feature_name, value_name, _ in features.feature_values_counts():\n        if feature_name not in expected_values:\n            expected_values[feature_name] = set()\n        expected_values[feature_name].add(value_name)\n\n    for person_id in people:\n        person_data = people.get_person_dict(person_id)\n\n        for feature_name, expected_vals in expected_values.items():\n            actual_val = person_data.get(feature_name, \"\")\n            if actual_val and actual_val not in expected_vals:\n                issues.append(\n                    f\"Person {person_id} has unexpected {feature_name} value: '{actual_val}'\"\n                )\n\n    # Check for duplicate IDs\n    seen_ids = set()\n    for person_id in people:\n        if person_id in seen_ids:\n            issues.append(f\"Duplicate person ID: {person_id}\")\n        seen_ids.add(person_id)\n\n    return issues\n\ndef clean_data_automatically(people_data: list[dict], features: FeatureCollection):\n    \"\"\"Automatically clean common data issues.\"\"\"\n\n    cleaned_data = []\n\n    for person in people_data:\n        cleaned_person = {}\n\n        for key, value in person.items():\n            # Strip whitespace\n            if isinstance(value, str):\n                value = value.strip()\n\n            # Standardize case for categorical variables\n            if key in features.feature_names:\n                # Convert to title case for consistency\n                value = value.title() if value else \"\"\n\n            cleaned_person[key] = value\n\n        # Skip records with missing required data\n        required_fields = [\"id\"] + features.feature_names\n        if all(cleaned_person.get(field) for field in required_fields):\n            cleaned_data.append(cleaned_person)\n\n    return cleaned_data\n</code></pre>"},{"location":"advanced/#performance-issues","title":"Performance Issues","text":"<p>Symptoms: Long runtime, memory errors, timeouts</p> <p>Diagnosis:</p> <pre><code>import time\nimport psutil\nimport tracemalloc\n\ndef profile_selection_performance():\n    \"\"\"Profile memory and CPU usage during selection.\"\"\"\n\n    # Start memory tracing\n    tracemalloc.start()\n\n    # Monitor CPU and memory\n    process = psutil.Process()\n    start_memory = process.memory_info().rss / 1024 / 1024  # MB\n    start_time = time.time()\n\n    try:\n        # Run your selection\n        success, panels, msgs = run_stratification(features, people, 100, settings)\n\n        # Measure resource usage\n        end_time = time.time()\n        end_memory = process.memory_info().rss / 1024 / 1024  # MB\n\n        current, peak = tracemalloc.get_traced_memory()\n        tracemalloc.stop()\n\n        print(f\"Runtime: {end_time - start_time:.2f} seconds\")\n        print(f\"Memory used: {end_memory - start_memory:.2f} MB\")\n        print(f\"Peak memory: {peak / 1024 / 1024:.2f} MB\")\n\n        return success, panels, msgs\n\n    except Exception as e:\n        tracemalloc.stop()\n        raise e\n</code></pre>"},{"location":"advanced/#debug-mode","title":"Debug Mode","text":"<p>Enable detailed debugging:</p> <pre><code>def debug_selection_process():\n    \"\"\"Run selection with comprehensive debugging.\"\"\"\n\n    import logging\n\n    # Set up detailed logging\n    logging.basicConfig(level=logging.DEBUG)\n    logger = logging.getLogger(__name__)\n\n    # Validate inputs\n    logger.info(\"Starting selection process validation...\")\n\n    # Check data quality\n    data_issues = audit_data_quality(people, features)\n    if data_issues:\n        logger.warning(f\"Found {len(data_issues)} data quality issues:\")\n        for issue in data_issues[:10]:  # Show first 10\n            logger.warning(f\"  - {issue}\")\n\n    # Check quota feasibility\n    quota_issues = diagnose_quota_feasibility(features, 100)\n    if quota_issues:\n        logger.error(\"Quota feasibility issues:\")\n        for issue in quota_issues:\n            logger.error(f\"  - {issue}\")\n        return False, [], [\"Quota issues prevent selection\"]\n\n    # Run selection with profiling\n    logger.info(\"Starting selection algorithm...\")\n    return profile_selection_performance()\n</code></pre>"},{"location":"advanced/#integration-patterns","title":"Integration Patterns","text":""},{"location":"advanced/#web-application-integration","title":"Web Application Integration","text":"<p>For Flask/Django applications:</p> <pre><code>from flask import Flask, request, jsonify, send_file\nimport tempfile\nimport os\n\napp = Flask(__name__)\n\n@app.route('/api/selection', methods=['POST'])\ndef run_selection_api():\n    try:\n        # Parse request\n        data = request.get_json()\n        panel_size = data['panel_size']\n        features_data = data['features']\n        people_data = data['people']\n\n        # Convert to library objects\n        features = create_features_from_data(features_data)\n        people = create_people_from_data(people_data)\n\n        # Run selection\n        settings = Settings()\n        success, panels, msgs = run_stratification(features, people, panel_size, settings)\n\n        if success:\n            # Format results\n            selected_table, remaining_table, _ = selected_remaining_tables(\n                people, panels[0], features, settings\n            )\n\n            return jsonify({\n                'success': True,\n                'selected_count': len(panels[0]),\n                'selected_ids': list(panels[0]),\n                'messages': msgs\n            })\n        else:\n            return jsonify({\n                'success': False,\n                'error': 'Selection failed',\n                'messages': msgs\n            }), 400\n\n    except Exception as e:\n        return jsonify({\n            'success': False,\n            'error': str(e)\n        }), 500\n\n@app.route('/api/selection/export/&lt;format&gt;')\ndef export_results(format):\n    # Implementation for exporting results in various formats\n    pass\n</code></pre>"},{"location":"advanced/#batch-processing-pipeline","title":"Batch Processing Pipeline","text":"<p>For automated processing:</p> <pre><code>import argparse\nimport sys\nfrom pathlib import Path\nfrom datetime import datetime\n\ndef batch_processing_pipeline():\n    \"\"\"Complete pipeline for batch processing multiple selections.\"\"\"\n\n    parser = argparse.ArgumentParser(description='Batch sortition processing')\n    parser.add_argument('--input-dir', type=Path, required=True)\n    parser.add_argument('--output-dir', type=Path, required=True)\n    parser.add_argument('--panel-sizes', nargs='+', type=int, default=[100])\n    parser.add_argument('--algorithms', nargs='+', default=['maximin'])\n\n    args = parser.parse_args()\n\n    # Create output directory\n    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n    run_dir = args.output_dir / f\"selection_run_{timestamp}\"\n    run_dir.mkdir(parents=True, exist_ok=True)\n\n    # Process each configuration\n    results_summary = []\n\n    for algorithm in args.algorithms:\n        for panel_size in args.panel_sizes:\n            try:\n                result = process_single_configuration(\n                    args.input_dir, run_dir, algorithm, panel_size\n                )\n                results_summary.append(result)\n\n            except Exception as e:\n                print(f\"Error processing {algorithm}/{panel_size}: {e}\")\n                results_summary.append({\n                    'algorithm': algorithm,\n                    'panel_size': panel_size,\n                    'success': False,\n                    'error': str(e)\n                })\n\n    # Generate summary report\n    generate_summary_report(run_dir, results_summary)\n\n    return results_summary\n\ndef process_single_configuration(input_dir: Path, output_dir: Path, algorithm: str, panel_size: int):\n    \"\"\"Process a single algorithm/panel size combination.\"\"\"\n\n    # Load data\n    adapter = CSVAdapter()\n    features, _ = adapter.load_features_from_file(input_dir / \"features.csv\")\n    people, _ = adapter.load_people_from_file(input_dir / \"people.csv\", Settings(), features)\n\n    # Configure settings\n    settings = Settings(\n        selection_algorithm=algorithm,\n        random_number_seed=42  # Reproducible for comparison\n    )\n\n    # Run selection\n    success, panels, msgs = run_stratification(features, people, panel_size, settings)\n\n    if success:\n        # Export results\n        selected_table, remaining_table, _ = selected_remaining_tables(\n            people, panels[0], features, settings\n        )\n\n        output_prefix = f\"{algorithm}_{panel_size}\"\n\n        with open(output_dir / f\"{output_prefix}_selected.csv\", \"w\", newline=\"\") as f:\n            adapter.selected_file = f\n            adapter._write_rows(f, selected_table)\n\n        with open(output_dir / f\"{output_prefix}_remaining.csv\", \"w\", newline=\"\") as f:\n            adapter.remaining_file = f\n            adapter._write_rows(f, remaining_table)\n\n    return {\n        'algorithm': algorithm,\n        'panel_size': panel_size,\n        'success': success,\n        'selected_count': len(panels[0]) if success else 0,\n        'messages': len(msgs)\n    }\n</code></pre>"},{"location":"advanced/#monitoring-and-alerting","title":"Monitoring and Alerting","text":"<p>For production deployments:</p> <pre><code>import smtplib\nfrom email.mime.text import MimeText\nfrom email.mime.multipart import MimeMultipart\n\nclass SelectionMonitor:\n    \"\"\"Monitor selection processes and send alerts.\"\"\"\n\n    def __init__(self, email_config: dict):\n        self.email_config = email_config\n\n    def monitor_selection(self, features, people, panel_size, settings):\n        \"\"\"Run selection with monitoring and alerting.\"\"\"\n\n        start_time = datetime.now()\n\n        try:\n            # Pre-flight checks\n            issues = self._pre_flight_checks(features, people, panel_size)\n            if issues:\n                self._send_alert(\"Pre-flight check failed\", \"\\n\".join(issues))\n                return False, [], issues\n\n            # Run selection\n            success, panels, msgs = run_stratification(features, people, panel_size, settings)\n\n            # Post-selection analysis\n            if success:\n                analysis = self._analyze_results(people, panels[0], features)\n                self._send_success_notification(analysis)\n            else:\n                self._send_alert(\"Selection failed\", \"\\n\".join(msgs))\n\n            return success, panels, msgs\n\n        except Exception as e:\n            self._send_alert(\"Selection error\", str(e))\n            raise\n\n        finally:\n            duration = datetime.now() - start_time\n            print(f\"Selection completed in {duration}\")\n\n    def _pre_flight_checks(self, features, people, panel_size):\n        \"\"\"Run pre-flight checks before selection.\"\"\"\n        issues = []\n\n        # Check pool size\n        if len(people) &lt; panel_size * 2:\n            issues.append(f\"Small candidate pool: {len(people)} for panel of {panel_size}\")\n\n        # Check quota feasibility\n        quota_issues = diagnose_quota_feasibility(features, panel_size)\n        issues.extend(quota_issues)\n\n        return issues\n\n    def _analyze_results(self, people, selected_panel, features):\n        \"\"\"Analyze selection results for quality metrics.\"\"\"\n\n        analysis = {\n            'panel_size': len(selected_panel),\n            'pool_size': len(people),\n            'selection_rate': len(selected_panel) / len(people),\n            'demographic_breakdown': {}\n        }\n\n        # Calculate demographic breakdown\n        for person_id in selected_panel:\n            person_data = people.get_person_dict(person_id)\n            for feature_name in features.feature_names:\n                feature_value = person_data.get(feature_name, \"Unknown\")\n                key = f\"{feature_name}:{feature_value}\"\n                analysis['demographic_breakdown'][key] = analysis['demographic_breakdown'].get(key, 0) + 1\n\n        return analysis\n\n    def _send_alert(self, subject: str, message: str):\n        \"\"\"Send email alert.\"\"\"\n        # Implementation depends on your email setup\n        print(f\"ALERT - {subject}: {message}\")\n\n    def _send_success_notification(self, analysis: dict):\n        \"\"\"Send success notification with analysis.\"\"\"\n        message = f\"Selection completed successfully. Panel size: {analysis['panel_size']}\"\n        print(f\"SUCCESS - {message}\")\n</code></pre>"},{"location":"advanced/#best-practices-summary","title":"Best Practices Summary","text":""},{"location":"advanced/#development-best-practices","title":"Development Best Practices","text":"<ol> <li>Always validate inputs: Check data quality before running selections</li> <li>Use appropriate random seeds: Fixed seeds for testing, None for production</li> <li>Handle errors gracefully: Provide meaningful error messages and recovery options</li> <li>Test with edge cases: Small pools, extreme quotas, missing data</li> <li>Monitor performance: Track memory usage and runtime for large datasets</li> </ol>"},{"location":"advanced/#production-best-practices","title":"Production Best Practices","text":"<ol> <li>Implement comprehensive logging: Track all selection attempts and results</li> <li>Set up monitoring and alerting: Detect failures and performance issues</li> <li>Use version control for configurations: Track changes to quotas and settings</li> <li>Backup candidate data: Ensure data persistence and recoverability</li> <li>Document selection criteria: Maintain audit trails for transparency</li> </ol>"},{"location":"advanced/#scaling-best-practices","title":"Scaling Best Practices","text":"<ol> <li>Optimize for your use case: Choose appropriate algorithms and settings</li> <li>Consider parallel processing: For multiple independent selections</li> <li>Implement caching: For expensive data loading operations</li> <li>Monitor resource usage: Plan capacity for peak loads</li> <li>Use appropriate hardware: SSDs for I/O intensive operations</li> </ol>"},{"location":"advanced/#next-steps","title":"Next Steps","text":"<ul> <li>Core Concepts - Understand sortition fundamentals</li> <li>Quick Start - Get started quickly</li> <li>API Reference - Complete function documentation</li> <li>CLI Usage - Command line interface</li> <li>Data Adapters - Working with different data sources</li> </ul>"},{"location":"api-reference/","title":"API Reference","text":"<p>Complete documentation for all public functions and classes in the sortition-algorithms library.</p>"},{"location":"api-reference/#core-functions","title":"Core Functions","text":""},{"location":"api-reference/#run_stratification","title":"run_stratification()","text":"<p>Main function for running stratified random selection with retry logic.</p> <pre><code>def run_stratification(\n    features: FeatureCollection,\n    people: People,\n    number_people_wanted: int,\n    settings: Settings,\n    test_selection: bool = False,\n    number_selections: int = 1,\n) -&gt; tuple[bool, list[frozenset[str]], list[str]]:\n</code></pre> <p>Parameters:</p> <ul> <li><code>features</code>: FeatureCollection with min/max quotas for each feature value</li> <li><code>people</code>: People object containing the pool of candidates</li> <li><code>number_people_wanted</code>: Desired size of the panel</li> <li><code>settings</code>: Settings object containing configuration</li> <li><code>test_selection</code>: If True, don't randomize (for testing only)</li> <li><code>number_selections</code>: Number of panels to return (usually 1)</li> </ul> <p>Returns:</p> <ul> <li><code>success</code>: Whether selection succeeded within max attempts</li> <li><code>selected_committees</code>: List of committees (frozensets of person IDs)</li> <li><code>output_lines</code>: Debug and status messages</li> </ul> <p>Raises:</p> <ul> <li><code>InfeasibleQuotasError</code>: If quotas cannot be satisfied</li> <li><code>SelectionError</code>: For various failure cases</li> <li><code>ValueError</code>: For invalid parameters</li> <li><code>RuntimeError</code>: If required solver is not available</li> </ul> <p>Example:</p> <pre><code>success, panels, messages = run_stratification(\n    features, people, 100, Settings()\n)\nif success:\n    selected_people = panels[0]  # frozenset of IDs\n</code></pre>"},{"location":"api-reference/#find_random_sample","title":"find_random_sample()","text":"<p>Lower-level algorithm function for finding random committees.</p> <pre><code>def find_random_sample(\n    features: FeatureCollection,\n    people: People,\n    number_people_wanted: int,\n    settings: Settings,\n    selection_algorithm: str = \"maximin\",\n    test_selection: bool = False,\n    number_selections: int = 1,\n) -&gt; tuple[list[frozenset[str]], list[str]]:\n</code></pre> <p>Parameters:</p> <ul> <li><code>selection_algorithm</code>: One of \"maximin\", \"leximin\", \"nash\", or \"legacy\"</li> <li>Other parameters same as <code>run_stratification()</code></li> </ul> <p>Returns:</p> <ul> <li><code>committee_lottery</code>: List of committees (may contain duplicates)</li> <li><code>output_lines</code>: Debug strings</li> </ul> <p>Example:</p> <pre><code>committees, messages = find_random_sample(\n    features, people, 50, settings, \"nash\"\n)\n</code></pre>"},{"location":"api-reference/#selected_remaining_tables","title":"selected_remaining_tables()","text":"<p>Format selection results for export to CSV or other formats.</p> <pre><code>def selected_remaining_tables(\n    full_people: People,\n    people_selected: frozenset[str],\n    features: FeatureCollection,\n    settings: Settings,\n) -&gt; tuple[list[list[str]], list[list[str]], list[str]]:\n</code></pre> <p>Parameters:</p> <ul> <li><code>full_people</code>: Original People object</li> <li><code>people_selected</code>: Single frozenset of selected person IDs</li> <li><code>features</code>: FeatureCollection used for selection</li> <li><code>settings</code>: Settings object</li> </ul> <p>Returns:</p> <ul> <li><code>selected_rows</code>: Table with selected people data</li> <li><code>remaining_rows</code>: Table with remaining people data</li> <li><code>output_lines</code>: Additional information messages</li> </ul> <p>Example:</p> <pre><code>selected_table, remaining_table, info = selected_remaining_tables(\n    people, selected_panel, features, settings\n)\n\n# Write to CSV\nimport csv\nwith open(\"selected.csv\", \"w\", newline=\"\") as f:\n    csv.writer(f).writerows(selected_table)\n</code></pre>"},{"location":"api-reference/#data-loading-functions","title":"Data Loading Functions","text":""},{"location":"api-reference/#read_in_features","title":"read_in_features()","text":"<p>Load feature definitions from a CSV file.</p> <pre><code>def read_in_features(features_file: str | Path) -&gt; FeatureCollection:\n</code></pre> <p>Parameters:</p> <ul> <li><code>features_file</code>: Path to CSV file with feature definitions</li> </ul> <p>Expected CSV format:</p> <pre><code>feature,value,min,max\nGender,Male,45,55\nGender,Female,45,55\nAge,18-30,20,30\n</code></pre> <p>Returns:</p> <ul> <li><code>FeatureCollection</code>: Object containing all features and quotas</li> </ul> <p>Example:</p> <pre><code>features = read_in_features(\"demographics.csv\")\n</code></pre>"},{"location":"api-reference/#read_in_people","title":"read_in_people()","text":"<p>Load candidate pool from a CSV file.</p> <pre><code>def read_in_people(\n    people_file: str | Path,\n    settings: Settings,\n    features: FeatureCollection\n) -&gt; People:\n</code></pre> <p>Parameters:</p> <ul> <li><code>people_file</code>: Path to CSV file with candidate data</li> <li><code>settings</code>: Settings object for configuration</li> <li><code>features</code>: FeatureCollection for validation</li> </ul> <p>Expected CSV format:</p> <pre><code>id,Name,Gender,Age,Email\np001,Alice,Female,18-30,alice@example.com\np002,Bob,Male,31-50,bob@example.com\n</code></pre> <p>Returns:</p> <ul> <li><code>People</code>: Object containing candidate pool</li> </ul> <p>Example:</p> <pre><code>people = read_in_people(\"candidates.csv\", settings, features)\n</code></pre>"},{"location":"api-reference/#settings-class","title":"Settings Class","text":"<p>Configuration object for customizing selection behavior.</p> <pre><code>class Settings:\n    def __init__(\n        self,\n        random_number_seed: int | None = None,\n        check_same_address: bool = False,\n        check_same_address_columns: list[str] | None = None,\n        selection_algorithm: str = \"maximin\",\n        max_attempts: int = 10,\n        columns_to_keep: list[str] | None = None,\n        id_column: str = \"id\",\n    ):\n</code></pre> <p>Parameters:</p> <ul> <li><code>random_number_seed</code>: Fixed seed for reproducible results (None = random)</li> <li><code>check_same_address</code>: Enable household diversity checking</li> <li><code>check_same_address_columns</code>: Columns that define an address</li> <li><code>selection_algorithm</code>: \"maximin\", \"leximin\", \"nash\", or \"legacy\"</li> <li><code>max_attempts</code>: Maximum selection retry attempts</li> <li><code>columns_to_keep</code>: Additional columns to include in output</li> <li><code>id_column</code>: Name of the ID column in people data</li> </ul> <p>Class Methods:</p>"},{"location":"api-reference/#settingsload_from_file","title":"Settings.load_from_file()","text":"<pre><code>@classmethod\ndef load_from_file(\n    cls,\n    settings_file_path: Path\n) -&gt; tuple[Settings, str]:\n</code></pre> <p>Load settings from a TOML file.</p> <p>Example settings.toml:</p> <pre><code>random_number_seed = 42\ncheck_same_address = true\ncheck_same_address_columns = [\"Address\", \"Postcode\"]\nselection_algorithm = \"maximin\"\nmax_attempts = 10\ncolumns_to_keep = [\"Name\", \"Email\", \"Phone\"]\n</code></pre> <p>Returns:</p> <ul> <li><code>Settings</code>: Configured settings object</li> <li><code>str</code>: Status message</li> </ul> <p>Example:</p> <pre><code>settings, msg = Settings.load_from_file(Path(\"config.toml\"))\nprint(msg)  # \"Settings loaded from config.toml\"\n</code></pre>"},{"location":"api-reference/#data-adapters","title":"Data Adapters","text":""},{"location":"api-reference/#csvadapter","title":"CSVAdapter","text":"<p>Handles CSV file input and output operations.</p> <pre><code>class CSVAdapter:\n    def load_features_from_file(\n        self, features_file: Path\n    ) -&gt; tuple[FeatureCollection, list[str]]:\n\n    def load_people_from_file(\n        self, people_file: Path, settings: Settings, features: FeatureCollection\n    ) -&gt; tuple[People, list[str]]:\n\n    def output_selected_remaining(\n        self, selected_rows: list[list[str]], remaining_rows: list[list[str]]\n    ) -&gt; None:\n</code></pre> <p>Example:</p> <pre><code>adapter = CSVAdapter()\nfeatures, msgs = adapter.load_features_from_file(Path(\"features.csv\"))\npeople, msgs = adapter.load_people_from_file(Path(\"people.csv\"), settings, features)\n\n# Set output files\nadapter.selected_file = open(\"selected.csv\", \"w\", newline=\"\")\nadapter.remaining_file = open(\"remaining.csv\", \"w\", newline=\"\")\nadapter.output_selected_remaining(selected_table, remaining_table)\n</code></pre>"},{"location":"api-reference/#gsheetadapter","title":"GSheetAdapter","text":"<p>Handles Google Sheets input and output operations.</p> <pre><code>class GSheetAdapter:\n    def __init__(\n        self,\n        credentials_file: Path,\n        gen_rem_tab: str = \"on\"\n    ):\n\n    def load_features(\n        self, gsheet_name: str, tab_name: str\n    ) -&gt; tuple[FeatureCollection | None, list[str]]:\n\n    def load_people(\n        self, tab_name: str, settings: Settings, features: FeatureCollection\n    ) -&gt; tuple[People | None, list[str]]:\n\n    def output_selected_remaining(\n        self, selected_rows: list[list[str]], remaining_rows: list[list[str]], settings: Settings\n    ) -&gt; None:\n</code></pre> <p>Parameters:</p> <ul> <li><code>credentials_file</code>: Path to Google API credentials JSON</li> <li><code>gen_rem_tab</code>: \"on\" or \"off\" to control remaining tab generation</li> </ul> <p>Example:</p> <pre><code>adapter = GSheetAdapter(Path(\"credentials.json\"))\nfeatures, msgs = adapter.load_features(\"My Spreadsheet\", \"Demographics\")\npeople, msgs = adapter.load_people(\"Candidates\", settings, features)\n\nadapter.selected_tab_name = \"Selected\"\nadapter.remaining_tab_name = \"Remaining\"\nadapter.output_selected_remaining(selected_table, remaining_table, settings)\n</code></pre>"},{"location":"api-reference/#core-data-classes","title":"Core Data Classes","text":""},{"location":"api-reference/#featurecollection","title":"FeatureCollection","text":"<p>Container for demographic features and their quotas.</p> <p>Key Methods:</p> <pre><code>def check_desired(self, number_people_wanted: int) -&gt; None:\n    # Validates that quotas are achievable for the desired panel size\n    # Raises exception if infeasible\n\ndef feature_names(self) -&gt; list[str]:\n    # Returns list of all feature names\n\ndef feature_values_counts(self) -&gt; Iterator[tuple[str, str, FeatureValueCounts]]:\n    # Iterate over all feature values and their count objects\n</code></pre>"},{"location":"api-reference/#people","title":"People","text":"<p>Container for the candidate pool.</p> <p>Key Methods:</p> <pre><code>def __len__(self) -&gt; int:\n    # Number of people in the pool\n\ndef __iter__(self) -&gt; Iterator[str]:\n    # Iterate over person IDs\n\ndef get_person_dict(self, person_id: str) -&gt; dict[str, str]:\n    # Get all data for a specific person\n\ndef matching_address(\n    self, person_id: str, address_columns: list[str]\n) -&gt; list[str]:\n    # Find people with matching address to given person\n\ndef remove(self, person_id: str) -&gt; None:\n    # Remove person from pool\n\ndef remove_many(self, person_ids: list[str]) -&gt; None:\n    # Remove multiple people from pool\n</code></pre>"},{"location":"api-reference/#error-classes","title":"Error Classes","text":""},{"location":"api-reference/#infeasiblequotaserror","title":"InfeasibleQuotasError","text":"<p>Raised when quotas cannot be satisfied with the available candidate pool.</p> <pre><code>class InfeasibleQuotasError(Exception):\n    def __init__(self, output: list[str])\n</code></pre> <p>Attributes:</p> <ul> <li><code>output</code>: List of diagnostic messages explaining the infeasibility</li> </ul>"},{"location":"api-reference/#selectionerror","title":"SelectionError","text":"<p>General error for selection process failures.</p> <pre><code>class SelectionError(Exception):\n    pass\n</code></pre>"},{"location":"api-reference/#utility-functions","title":"Utility Functions","text":""},{"location":"api-reference/#set_random_provider","title":"set_random_provider()","text":"<p>Configure the random number generator for reproducible results.</p> <pre><code>def set_random_provider(seed: int | None) -&gt; None\n</code></pre> <p>Parameters:</p> <ul> <li><code>seed</code>: Random seed (None for secure random)</li> </ul> <p>Example:</p> <pre><code>set_random_provider(42)  # Reproducible results\nset_random_provider(None)  # Secure random\n</code></pre>"},{"location":"api-reference/#type-hints","title":"Type Hints","text":"<p>Common type aliases used throughout the API:</p> <pre><code># A committee is a set of person IDs\nCommittee = frozenset[str]\n\n# Selection results are lists of committees\nSelectionResult = list[Committee]\n\n# Tables are lists of rows (lists of strings)\nTable = list[list[str]]\n</code></pre>"},{"location":"cli/","title":"Command Line Interface","text":"<p>The CLI provides a convenient way to run sortition algorithms without writing Python code. It's ideal for:</p> <ul> <li>One-off selections: Quick panel selections for events or research</li> <li>Batch processing: Running multiple selections with scripts</li> <li>Non-programmers: Teams who prefer command-line tools</li> <li>Integration: Incorporating sortition into existing workflows</li> </ul>"},{"location":"cli/#installation","title":"Installation","text":"<p>Install the CLI with optional dependencies:</p> <pre><code># Basic installation\npip install 'sortition-algorithms[cli]'\n\n# With Gurobi support for leximin algorithm\npip install 'sortition-algorithms[cli,gurobi]'\n</code></pre>"},{"location":"cli/#quick-start","title":"Quick Start","text":"<pre><code># Check installation\npython -m sortition_algorithms --help\n\n# Basic CSV selection\npython -m sortition_algorithms csv \\\n  --settings config.toml \\\n  --features-csv demographics.csv \\\n  --people-csv candidates.csv \\\n  --selected-csv selected.csv \\\n  --remaining-csv remaining.csv \\\n  --number-wanted 100\n</code></pre>"},{"location":"cli/#commands-overview","title":"Commands Overview","text":"<p>The CLI provides three main commands:</p> <pre><code>$ python -m sortition_algorithms --help\nUsage: python -m sortition_algorithms [OPTIONS] COMMAND [ARGS]...\n\n  A command line tool to exercise the sortition algorithms.\n\nOptions:\n  --help  Show this message and exit.\n\nCommands:\n  csv         Do sortition with CSV files\n  gen-sample  Generate sample CSV file compatible with features\n  gsheet      Do sortition with Google Spreadsheets\n</code></pre>"},{"location":"cli/#csv-workflow","title":"CSV Workflow","text":"<p>The most common usage pattern for working with local CSV files.</p>"},{"location":"cli/#command-reference","title":"Command Reference","text":"<pre><code>$ python -m sortition_algorithms csv --help\nUsage: python -m sortition_algorithms csv [OPTIONS]\n\n  Do sortition with CSV files.\n\nOptions:\n  -S, --settings FILE             Settings file (TOML format) [required]\n  -f, --features-csv FILE         CSV with demographic features [required]\n  -p, --people-csv FILE           CSV with candidate pool [required]\n  -s, --selected-csv FILE         Output: selected people [required]\n  -r, --remaining-csv FILE        Output: remaining people [required]\n  -n, --number-wanted INTEGER     Number of people to select [required]\n  --help                          Show this message and exit.\n</code></pre>"},{"location":"cli/#example-files","title":"Example Files","text":"<p>demographics.csv (feature definitions):</p> <pre><code>feature,value,min,max\nGender,Male,45,55\nGender,Female,45,55\nAge,18-30,20,30\nAge,31-50,35,45\nAge,51+,25,35\nLocation,Urban,40,60\nLocation,Rural,40,60\n</code></pre> <p>candidates.csv (candidate pool):</p> <pre><code>id,Name,Email,Gender,Age,Location,Address,Postcode\np001,Alice Smith,alice@email.com,Female,18-30,Urban,123 Main St,12345\np002,Bob Jones,bob@email.com,Male,31-50,Rural,456 Oak Ave,67890\np003,Carol Davis,carol@email.com,Female,51+,Urban,789 Pine Rd,12345\n...\n</code></pre> <p>config.toml (settings):</p> <pre><code># Reproducible results\nrandom_number_seed = 42\n\n# Household diversity\ncheck_same_address = true\ncheck_same_address_columns = [\"Address\", \"Postcode\"]\n\n# Algorithm choice\nselection_algorithm = \"maximin\"\nmax_attempts = 10\n\n# Output customization\ncolumns_to_keep = [\"Name\", \"Email\", \"Phone\"]\nid_column = \"id\"\n</code></pre>"},{"location":"cli/#basic-selection","title":"Basic Selection","text":"<pre><code>python -m sortition_algorithms csv \\\n  --settings config.toml \\\n  --features-csv demographics.csv \\\n  --people-csv candidates.csv \\\n  --selected-csv selected.csv \\\n  --remaining-csv remaining.csv \\\n  --number-wanted 100\n</code></pre>"},{"location":"cli/#using-environment-variables","title":"Using Environment Variables","text":"<p>Set commonly used paths as environment variables:</p> <pre><code>export SORTITION_SETTINGS=\"config.toml\"\nexport SORTITION_FEATURES=\"demographics.csv\"\nexport SORTITION_PEOPLE=\"candidates.csv\"\n\npython -m sortition_algorithms csv \\\n  -s selected.csv \\\n  -r remaining.csv \\\n  -n 100\n</code></pre>"},{"location":"cli/#batch-processing","title":"Batch Processing","text":"<p>Create a script for multiple selections:</p> <pre><code>#!/bin/bash\n# batch_selection.sh\n\nSETTINGS=\"config.toml\"\nFEATURES=\"demographics.csv\"\nPEOPLE=\"candidates.csv\"\nSIZES=(50 75 100 125 150)\n\nfor size in \"${SIZES[@]}\"; do\n    echo \"Selecting $size people...\"\n    python -m sortition_algorithms csv \\\n        --settings \"$SETTINGS\" \\\n        --features-csv \"$FEATURES\" \\\n        --people-csv \"$PEOPLE\" \\\n        --selected-csv \"selected_${size}.csv\" \\\n        --remaining-csv \"remaining_${size}.csv\" \\\n        --number-wanted \"$size\"\ndone\n</code></pre> <p>Note that to actually do selections with multiple sizes, you'd also need to be adjusting the min and max values in the quotas at the same time.</p>"},{"location":"cli/#google-sheets-workflow","title":"Google Sheets Workflow","text":"<p>For organizations using Google Sheets for data management.</p>"},{"location":"cli/#setup-requirements","title":"Setup Requirements","text":"<ol> <li>Google Cloud Project: Create a project in Google Cloud Console</li> <li>Enable APIs: Enable Google Sheets API and Google Drive API</li> <li>Service Account: Create service account credentials</li> <li>Share Sheet: Share your spreadsheet with the service account email</li> </ol>"},{"location":"cli/#command-reference_1","title":"Command Reference","text":"<pre><code>$ python -m sortition_algorithms gsheet --help\nUsage: python -m sortition_algorithms gsheet [OPTIONS]\n\n  Do sortition with Google Spreadsheets.\n\nOptions:\n  -S, --settings FILE             Settings file (TOML format) [required]\n  --auth-json-file FILE           Google API credentials JSON [required]\n  --gen-rem-tab / --no-gen-rem-tab Generate 'Remaining' tab [default: true]\n  -g, --gsheet-name TEXT          Spreadsheet name [required]\n  -f, --feature-tab-name TEXT     Features tab name [default: Categories]\n  -p, --people-tab-name TEXT      People tab name [default: Categories]\n  -s, --selected-tab-name TEXT    Selected output tab [default: Selected]\n  -r, --remaining-tab-name TEXT   Remaining output tab [default: Remaining]\n  -n, --number-wanted INTEGER     Number of people to select [required]\n  --help                          Show this message and exit.\n</code></pre>"},{"location":"cli/#authentication-setup","title":"Authentication Setup","text":"<ol> <li>Download service account credentials JSON file</li> <li>Never commit this file to version control</li> <li>Store securely and reference by path</li> </ol>"},{"location":"cli/#example-usage","title":"Example Usage","text":"<pre><code>python -m sortition_algorithms gsheet \\\n  --settings config.toml \\\n  --auth-json-file /secure/path/credentials.json \\\n  --gsheet-name \"Citizen Panel 2024\" \\\n  --feature-tab-name \"Demographics\" \\\n  --people-tab-name \"Candidates\" \\\n  --selected-tab-name \"Selected Panel\" \\\n  --remaining-tab-name \"Reserve Pool\" \\\n  --number-wanted 120\n</code></pre>"},{"location":"cli/#spreadsheet-structure","title":"Spreadsheet Structure","text":"<p>Your Google Sheet should have tabs structured like this:</p> <p>Demographics tab:</p> feature value min max Gender Male 45 55 Gender Female 45 55 Age 18-30 20 30 <p>Candidates tab:</p> id Name Email Gender Age Location p001 Alice alice@email.com Female 18-30 Urban p002 Bob bob@email.com Male 31-50 Rural"},{"location":"cli/#sample-generation","title":"Sample Generation","text":"<p>Generate test data compatible with your feature definitions.</p>"},{"location":"cli/#command-reference_2","title":"Command Reference","text":"<pre><code>$ python -m sortition_algorithms gen-sample --help\nUsage: python -m sortition_algorithms gen-sample [OPTIONS]\n\n  Generate sample CSV file compatible with features and settings.\n\nOptions:\n  -S, --settings FILE             Settings file [required]\n  -f, --features-csv FILE         Features CSV file [required]\n  -p, --people-csv FILE           Output: generated people CSV [required]\n  -n, --number-wanted INTEGER     Number of people to generate [required]\n  --help                          Show this message and exit.\n</code></pre>"},{"location":"cli/#example-usage_1","title":"Example Usage","text":"<pre><code># Generate 500 sample people\npython -m sortition_algorithms gen-sample \\\n  --settings config.toml \\\n  --features-csv demographics.csv \\\n  --people-csv sample_candidates.csv \\\n  --number-wanted 500\n</code></pre> <p>This creates a CSV with realistic synthetic data that matches your feature definitions - useful for testing quotas and algorithms.</p>"},{"location":"cli/#configuration-files","title":"Configuration Files","text":""},{"location":"cli/#settings-file-format","title":"Settings File Format","text":"<p>All settings are optional and have sensible defaults:</p> <pre><code># config.toml\n\n# Randomization\nrandom_number_seed = 42  # Set for reproducible results, omit for random\n\n# Address checking for household diversity\ncheck_same_address = true\ncheck_same_address_columns = [\"Address\", \"Postcode\", \"City\"]\n\n# Algorithm selection\nselection_algorithm = \"maximin\"  # \"maximin\", \"nash\", \"leximin\", \"legacy\"\nmax_attempts = 10\n\n# Output customization\ncolumns_to_keep = [\"Name\", \"Email\", \"Phone\", \"Notes\"]\nid_column = \"id\"  # Column name containing unique IDs\n</code></pre>"},{"location":"cli/#algorithm-comparison","title":"Algorithm Comparison","text":"Algorithm Pros Cons Use Case <code>maximin</code> Fair to minorities May not optimize overall Default choice <code>nash</code> Balanced overall Complex optimization Large diverse pools <code>leximin</code> Strongest fairness Requires Gurobi license Academic/research <code>legacy</code> Backwards compatible Less sophisticated Historical consistency"},{"location":"cli/#common-workflows","title":"Common Workflows","text":""},{"location":"cli/#standard-selection-process","title":"Standard Selection Process","text":"<pre><code># 1. Prepare your data files\n# 2. Configure settings\n# 3. Run selection\npython -m sortition_algorithms csv \\\n  --settings config.toml \\\n  --features-csv demographics.csv \\\n  --people-csv candidates.csv \\\n  --selected-csv selected.csv \\\n  --remaining-csv remaining.csv \\\n  --number-wanted 100\n\n# 4. Review results\nhead selected.csv\nwc -l remaining.csv\n</code></pre>"},{"location":"cli/#with-address-checking","title":"With Address Checking","text":"<p>Ensure household diversity by preventing multiple selections from the same address:</p> <pre><code># config.toml\ncheck_same_address = true\ncheck_same_address_columns = [\"Address\", \"Postcode\"]\n</code></pre>"},{"location":"cli/#reproducible-selections","title":"Reproducible Selections","text":"<p>For auditable results, use a fixed random seed:</p> <pre><code># config.toml\nrandom_number_seed = 20241214  # Use today's date or similar\n</code></pre>"},{"location":"cli/#testing-quotas","title":"Testing Quotas","text":"<p>Use sample generation to test if your quotas are achievable:</p> <pre><code># Generate large sample\npython -m sortition_algorithms gen-sample \\\n  --settings config.toml \\\n  --features-csv demographics.csv \\\n  --people-csv test_pool.csv \\\n  --number-wanted 1000\n\n# Test selection\npython -m sortition_algorithms csv \\\n  --settings config.toml \\\n  --features-csv demographics.csv \\\n  --people-csv test_pool.csv \\\n  --selected-csv test_selected.csv \\\n  --remaining-csv test_remaining.csv \\\n  --number-wanted 100\n</code></pre>"},{"location":"cli/#troubleshooting","title":"Troubleshooting","text":""},{"location":"cli/#common-errors","title":"Common Errors","text":"<p>\"Selection failed\"</p> <ul> <li>Check that quota minimums don't exceed panel size</li> <li>Verify feature values match between files</li> <li>Review constraint feasibility</li> </ul> <p>\"File not found\"</p> <ul> <li>Use absolute paths or verify working directory</li> <li>Check file permissions</li> <li>Ensure files exist before running</li> </ul> <p>\"Invalid feature values\"</p> <ul> <li>Verify exact string matching between demographics.csv and candidates.csv</li> <li>Check for typos, case sensitivity, extra spaces</li> <li>Review non-ASCII characters</li> </ul> <p>\"Authentication failed\" (Google Sheets)</p> <ul> <li>Verify credentials.json is correct and accessible</li> <li>Check that service account has access to the spreadsheet</li> <li>Ensure APIs are enabled in Google Cloud Console</li> </ul>"},{"location":"cli/#debug-tips","title":"Debug Tips","text":"<p>Verbose output: The CLI provides detailed messages about the selection process.</p> <p>Test with smaller numbers: If selection fails, try reducing <code>--number-wanted</code> to isolate the issue.</p> <p>Check intermediate files: Use <code>gen-sample</code> to create test data and verify your workflow.</p> <p>Environment variables: Set <code>SORTITION_SETTINGS</code> to avoid repeating file paths.</p>"},{"location":"cli/#getting-help","title":"Getting Help","text":"<pre><code># General help\npython -m sortition_algorithms --help\n\n# Command-specific help\npython -m sortition_algorithms csv --help\npython -m sortition_algorithms gsheet --help\npython -m sortition_algorithms gen-sample --help\n</code></pre>"},{"location":"cli/#integration-examples","title":"Integration Examples","text":""},{"location":"cli/#shell-scripts","title":"Shell Scripts","text":"<pre><code>#!/bin/bash\n# run_selection.sh\n\nset -e  # Exit on error\n\necho \"Starting selection process...\"\n\npython -m sortition_algorithms csv \\\n  --settings \"${SORTITION_SETTINGS}\" \\\n  --features-csv \"${FEATURES_FILE}\" \\\n  --people-csv \"${PEOPLE_FILE}\" \\\n  --selected-csv \"selected_$(date +%Y%m%d).csv\" \\\n  --remaining-csv \"remaining_$(date +%Y%m%d).csv\" \\\n  --number-wanted \"${PANEL_SIZE}\"\n\necho \"Selection completed successfully!\"\n</code></pre>"},{"location":"cli/#cicd-integration","title":"CI/CD Integration","text":"<pre><code># .github/workflows/selection.yml\nname: Run Selection\non:\n  workflow_dispatch:\n    inputs:\n      panel_size:\n        description: \"Number of people to select\"\n        required: true\n        default: \"100\"\n\njobs:\n  select:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v3\n      - uses: actions/setup-python@v4\n        with:\n          python-version: \"3.11\"\n      - run: pip install 'sortition-algorithms[cli]'\n      - run: |\n          python -m sortition_algorithms csv \\\n            --settings config.toml \\\n            --features-csv data/demographics.csv \\\n            --people-csv data/candidates.csv \\\n            --selected-csv selected.csv \\\n            --remaining-csv remaining.csv \\\n            --number-wanted ${{ github.event.inputs.panel_size }}\n      - uses: actions/upload-artifact@v3\n        with:\n          name: selection-results\n          path: |\n            selected.csv\n            remaining.csv\n</code></pre>"},{"location":"cli/#next-steps","title":"Next Steps","text":"<ul> <li>Core Concepts - Understand the theory behind sortition</li> <li>API Reference - For programmatic usage</li> <li>Data Adapters - Custom data sources and formats</li> <li>Advanced Usage - Complex scenarios and optimization</li> </ul>"},{"location":"concepts/","title":"Core Concepts","text":"<p>Understanding these fundamental concepts is essential for effectively using sortition algorithms.</p>"},{"location":"concepts/#what-is-sortition","title":"What is Sortition?","text":"<p>Sortition is the random selection of representatives from a larger population, designed to create panels that reflect the demographic composition of the whole group. Unlike simple random sampling (which could accidentally select all men or all young people), sortition uses stratified random selection to ensure demographic balance.</p>"},{"location":"concepts/#historical-context","title":"Historical Context","text":"<p>Sortition has ancient roots in Athenian democracy, where citizens were chosen by lot to serve in government. Modern applications include:</p> <ul> <li>Citizens' Assemblies: Groups that deliberate on policy issues</li> <li>Deliberative Polls: Representative samples for public opinion research</li> <li>Jury Selection: Court juries selected from voter rolls</li> <li>Participatory Budgeting: Community members deciding budget priorities</li> </ul>"},{"location":"concepts/#key-components","title":"Key Components","text":""},{"location":"concepts/#features-and-feature-values","title":"Features and Feature Values","text":"<p>Features are demographic characteristics used for stratification:</p> <ul> <li>Gender, Age, Education, Income, Location, etc.</li> </ul> <p>Feature Values are the specific categories within each feature:</p> <ul> <li>Gender: Male, Female, Non-binary</li> <li>Age: 18-30, 31-50, 51-65, 65+</li> <li>Location: Urban, Suburban, Rural</li> </ul>"},{"location":"concepts/#quotas-and-targets","title":"Quotas and Targets","text":"<p>Each feature value has minimum and maximum quotas that define the acceptable range for selection:</p> <pre><code>feature,value,min,max\nGender,Male,45,55\nGender,Female,45,55\nAge,18-30,20,30\nAge,31-50,30,40\nAge,51+,25,35\n</code></pre> <p>This ensures your panel of 100 people includes 45-55 men, 45-55 women, 20-30 young adults, etc.</p>"},{"location":"concepts/#people-pool","title":"People Pool","text":"<p>The candidate pool contains all eligible individuals with their demographic data:</p> <pre><code>id,Name,Gender,Age,Location,Email\np001,Alice Smith,Female,18-30,Urban,alice@example.com\np002,Bob Jones,Male,31-50,Rural,bob@example.com\n...\n</code></pre>"},{"location":"concepts/#address-checking-and-household-diversity","title":"Address Checking and Household Diversity","text":"<p>A critical feature for ensuring true representativeness is address checking - preventing multiple people from the same household being selected.</p>"},{"location":"concepts/#why-address-checking-matters","title":"Why Address Checking Matters","text":"<p>Without address checking, you might accidentally select:</p> <ul> <li>Multiple family members with similar views</li> <li>Several housemates from a shared address</li> <li>People who influence each other's opinions</li> </ul> <p>This reduces the independence and diversity of your panel.</p>"},{"location":"concepts/#how-it-works","title":"How It Works","text":"<p>Configure address checking in your settings:</p> <pre><code>settings = Settings(\n    check_same_address=True,\n    check_same_address_columns=[\"Address\", \"Postcode\"]\n)\n</code></pre> <p>When someone is selected:</p> <ol> <li>The algorithm identifies anyone else with matching values in the specified columns</li> <li>Those people are removed from the remaining pool</li> <li>This ensures geographic and household diversity</li> </ol>"},{"location":"concepts/#address-column-strategies","title":"Address Column Strategies","text":"<p>Single column approach:</p> <pre><code>check_same_address_columns = [\"Full_Address\"]\n</code></pre> <p>Multi-column approach (more flexible):</p> <pre><code>check_same_address_columns = [\"Street\", \"City\", \"Postcode\"]\n</code></pre> <p>Exact vs. fuzzy matching: The current implementation requires exact string matches. For fuzzy address matching, you'd need to clean your data first.</p>"},{"location":"concepts/#selection-algorithms","title":"Selection Algorithms","text":"<p>Different algorithms optimize for different fairness criteria:</p>"},{"location":"concepts/#maximin-default","title":"Maximin (Default)","text":"<ul> <li>Goal: Maximize the minimum selection probability</li> <li>Good for: Ensuring no group is severely underrepresented</li> <li>Trade-off: May not optimize overall fairness</li> </ul>"},{"location":"concepts/#nash","title":"Nash","text":"<ul> <li>Goal: Maximize the product of all selection probabilities</li> <li>Good for: Balanced representation across all groups</li> <li>Trade-off: Complex optimization, harder to interpret</li> </ul>"},{"location":"concepts/#leximin","title":"Leximin","text":"<ul> <li>Goal: Lexicographic maximin (requires Gurobi license)</li> <li>Good for: Strict fairness guarantees</li> <li>Trade-off: Requires commercial solver</li> </ul>"},{"location":"concepts/#legacy","title":"Legacy","text":"<ul> <li>Goal: Backwards compatibility with older implementations</li> <li>Good for: Reproducing historical selections</li> <li>Trade-off: Less sophisticated than modern algorithms</li> </ul>"},{"location":"concepts/#the-selection-process","title":"The Selection Process","text":""},{"location":"concepts/#1-feasibility-checking","title":"1. Feasibility Checking","text":"<p>Before selection begins, the algorithm verifies that quotas are achievable:</p> <pre><code>features.check_desired(number_people_wanted=100)\n</code></pre>"},{"location":"concepts/#2-algorithm-execution","title":"2. Algorithm Execution","text":"<p>The chosen algorithm finds an optimal probability distribution over possible committees.</p>"},{"location":"concepts/#3-lottery-rounding","title":"3. Lottery Rounding","text":"<p>The probability distribution is converted to concrete selections using randomized rounding.</p>"},{"location":"concepts/#4-validation","title":"4. Validation","text":"<p>Selected committees are checked against quotas to ensure targets were met.</p>"},{"location":"concepts/#randomness-and-reproducibility","title":"Randomness and Reproducibility","text":""},{"location":"concepts/#random-seeds","title":"Random Seeds","text":"<p>For reproducible results (e.g., for auditing), set a random seed:</p> <pre><code>settings = Settings(random_number_seed=42)\n</code></pre>"},{"location":"concepts/#security-considerations","title":"Security Considerations","text":"<p>For production use, avoid fixed seeds. The library uses Python's <code>secrets</code> module when no seed is specified.</p>"},{"location":"concepts/#data-quality-considerations","title":"Data Quality Considerations","text":""},{"location":"concepts/#feature-consistency","title":"Feature Consistency","text":"<p>Ensure feature values are consistent between your quotas file and candidate data:</p> <pre><code># demographics.csv\nGender,Male,45,55\nGender,Female,45,55\n\n# candidates.csv - values must match exactly\nperson1,Male,...    # \u2705 Matches\nperson2,male,...    # \u274c Case mismatch\nperson3,M,...       # \u274c Abbreviation mismatch\n</code></pre>"},{"location":"concepts/#missing-data","title":"Missing Data","text":"<p>The library requires complete demographic data. Handle missing values before import:</p> <ul> <li>Impute missing values</li> <li>Create \"Unknown\" categories</li> <li>Exclude incomplete records</li> </ul>"},{"location":"concepts/#data-validation","title":"Data Validation","text":"<p>The library performs extensive validation:</p> <ul> <li>Checks for unknown feature values</li> <li>Verifies quota feasibility</li> <li>Validates candidate pool size</li> </ul>"},{"location":"concepts/#error-handling","title":"Error Handling","text":""},{"location":"concepts/#common-errors","title":"Common Errors","text":"<p>InfeasibleQuotasError: Your quotas cannot be satisfied</p> <pre><code># Too restrictive - asking for 90+ males in a pool of 100\nGender,Male,90,100\nGender,Female,90,100\n</code></pre> <p>SelectionError: General selection failures</p> <ul> <li>Insufficient candidates in a category</li> <li>Conflicting constraints</li> </ul> <p>ValueError: Invalid parameters</p> <ul> <li>Negative quotas</li> <li>Invalid algorithm names</li> </ul>"},{"location":"concepts/#debugging-tips","title":"Debugging Tips","text":"<ol> <li>Check quota feasibility: Sum of minimums \u2264 panel size \u2264 sum of maximums</li> <li>Verify data consistency: Feature values match between files</li> <li>Review messages: The algorithm provides detailed feedback</li> <li>Test with relaxed quotas: Temporarily widen ranges to isolate issues</li> </ol>"},{"location":"concepts/#best-practices","title":"Best Practices","text":""},{"location":"concepts/#quota-design","title":"Quota Design","text":"<ul> <li>Start conservative: Use wider ranges initially, then narrow if needed</li> <li>Consider interactions: Age and education might be correlated</li> <li>Plan for edge cases: What if you have few candidates in a category?</li> </ul>"},{"location":"concepts/#data-preparation","title":"Data Preparation","text":"<ul> <li>Standardize values: Consistent capitalization and spelling</li> <li>Validate completeness: No missing demographic data</li> <li>Test with samples: Verify your setup with small test runs</li> </ul>"},{"location":"concepts/#address-checking","title":"Address Checking","text":"<ul> <li>Clean addresses first: Standardize formatting before using address checking</li> <li>Consider geography: Urban areas might need tighter address matching</li> <li>Balance household diversity vs. other constraints: Address checking reduces your effective pool size</li> </ul>"},{"location":"concepts/#next-steps","title":"Next Steps","text":"<p>Now that you understand the core concepts:</p> <ul> <li>Quick Start - Try your first selection</li> <li>API Reference - Detailed function documentation</li> <li>CLI Usage - Command line examples</li> <li>Data Adapters - Working with different data sources</li> <li>Advanced Usage - Complex scenarios and optimization</li> </ul>"},{"location":"modules/","title":"Modules","text":"<p>Adapters for loading and saving data.</p> <p>Initially we have CSV files locally, and Google Docs Spreadsheets.</p> <p>Selection algorithms for stratified sampling.</p>"},{"location":"modules/#sortition_algorithms.adapters.GSheetAdapter","title":"<code>GSheetAdapter</code>","text":"Source code in <code>src/sortition_algorithms/adapters.py</code> <pre><code>class GSheetAdapter:\n    scope: ClassVar = [\n        \"https://spreadsheets.google.com/feeds\",\n        \"https://www.googleapis.com/auth/drive\",\n    ]\n    hl_light_blue: ClassVar = {\n        \"backgroundColor\": {\n            \"red\": 153 / 255,\n            \"green\": 204 / 255,\n            \"blue\": 255 / 255,\n        }\n    }\n    hl_orange: ClassVar = {\"backgroundColor\": {\"red\": 5, \"green\": 2.5, \"blue\": 0}}\n\n    def __init__(self, auth_json_path: Path, gen_rem_tab: str = \"on\") -&gt; None:\n        self.auth_json_path = auth_json_path\n        self._client: gspread.client.Client | None = None\n        self._spreadsheet: gspread.Spreadsheet | None = None\n        self.original_selected_tab_name = \"Original Selected - output - \"\n        self.selected_tab_name = \"Selected\"\n        self.columns_selected_first = \"C\"\n        self.column_selected_blank_num = 6\n        self.remaining_tab_name = \"Remaining - output - \"\n        self.new_tab_default_size_rows = 2\n        self.new_tab_default_size_cols = 40\n        self.g_sheet_name = \"\"\n        self._messages: list[str] = []\n        self.features_loaded = False\n        self.people_loaded = False\n        self.gen_rem_tab = gen_rem_tab  # Added for checkbox.\n\n    def messages(self) -&gt; list[str]:\n        \"\"\"Return accumulated messages and reset\"\"\"\n        messages = self._messages\n        self._messages = []\n        return messages\n\n    @property\n    def client(self) -&gt; gspread.client.Client:\n        if self._client is None:\n            creds = ServiceAccountCredentials.from_json_keyfile_name(\n                str(self.auth_json_path),\n                self.scope,\n            )\n            self._client = gspread.authorize(creds)\n        return self._client\n\n    @property\n    def spreadsheet(self) -&gt; gspread.Spreadsheet:\n        if self._spreadsheet is None:\n            self._spreadsheet = self.client.open(self.g_sheet_name)\n            self._messages.append(f\"Opened Google Sheet: '{self.g_sheet_name}'. \")\n        return self._spreadsheet\n\n    def _tab_exists(self, tab_name: str) -&gt; bool:\n        if self.spreadsheet is None:\n            return False\n        tab_list = self.spreadsheet.worksheets()\n        return any(tab.title == tab_name for tab in tab_list)\n\n    def _clear_or_create_tab(self, tab_name: str, other_tab_name: str, inc: int) -&gt; gspread.Worksheet:\n        # this now does not clear data but increments the sheet number...\n        num = 0\n        tab_ready: gspread.Worksheet | None = None\n        tab_name_new = f\"{tab_name}{num}\"\n        other_tab_name_new = f\"{other_tab_name}{num}\"\n        while tab_ready is None:\n            if self._tab_exists(tab_name_new) or self._tab_exists(other_tab_name_new):\n                num += 1\n                tab_name_new = f\"{tab_name}{num}\"\n                other_tab_name_new = f\"{other_tab_name}{num}\"\n            else:\n                if inc == -1:\n                    tab_name_new = f\"{tab_name}{num - 1}\"\n                tab_ready = self.spreadsheet.add_worksheet(\n                    title=tab_name_new,\n                    rows=self.new_tab_default_size_rows,\n                    cols=self.new_tab_default_size_cols,\n                )\n        return tab_ready\n\n    def load_features(self, g_sheet_name: str, feature_tab_name: str) -&gt; tuple[FeatureCollection | None, list[str]]:\n        self.g_sheet_name = g_sheet_name\n        features: FeatureCollection | None = None\n        try:\n            if not self._tab_exists(feature_tab_name):\n                self._messages.append(f\"Error in Google sheet: no tab called '{feature_tab_name}' found. \")\n                return None, self.messages()\n        except gspread.SpreadsheetNotFound:\n            self._messages.append(f\"Google spreadsheet not found: {self.g_sheet_name}. \")\n            return None, self.messages()\n        tab_features = self.spreadsheet.worksheet(feature_tab_name)\n        feature_head = tab_features.row_values(1)\n        feature_body = _stringify_records(tab_features.get_all_records(expected_headers=[]))\n        features, msgs = read_in_features(feature_head, feature_body)\n        self.features_loaded = True\n        self._messages += msgs\n        return features, self.messages()\n\n    def load_people(\n        self,\n        respondents_tab_name: str,\n        settings: Settings,\n        features: FeatureCollection,\n    ) -&gt; tuple[People | None, list[str]]:\n        self._messages = []\n        people: People | None = None\n        try:\n            if not self._tab_exists(respondents_tab_name):\n                self._messages.append(\n                    f\"Error in Google sheet: no tab called '{respondents_tab_name}' found. \",\n                )\n                return None, self.messages()\n        except gspread.SpreadsheetNotFound:\n            self._messages.append(f\"Google spreadsheet not found: {self.g_sheet_name}. \")\n            return None, self.messages()\n\n        tab_people = self.spreadsheet.worksheet(respondents_tab_name)\n        # if we don't read this in here we can't check if there are 2 columns with the same name\n        people_head = tab_people.row_values(1)\n        # the numericise_ignore doesn't convert the phone numbers to ints...\n        # 1 Oct 2024: the final argument with expected_headers is to deal with the fact that\n        # updated versions of gspread can't cope with duplicate headers\n        people_body = _stringify_records(\n            tab_people.get_all_records(\n                numericise_ignore=[\"all\"],\n                expected_headers=[],\n            )\n        )\n        self._messages.append(f\"Reading in '{respondents_tab_name}' tab in above Google sheet.\")\n        people, msgs = read_in_people(people_head, people_body, features, settings)\n        self._messages += msgs\n        self.people_loaded = True\n        return people, self.messages()\n\n    def output_selected_remaining(\n        self,\n        people_selected_rows: list[list[str]],\n        people_remaining_rows: list[list[str]],\n        settings: Settings,\n    ) -&gt; list[int]:\n        tab_original_selected = self._clear_or_create_tab(\n            self.original_selected_tab_name,\n            self.remaining_tab_name,\n            0,\n        )\n        tab_original_selected.update(people_selected_rows)\n        tab_original_selected.format(\"A1:U1\", self.hl_light_blue)\n        dupes: list[int] = []\n        if self.gen_rem_tab == \"on\":\n            tab_remaining = self._clear_or_create_tab(\n                self.remaining_tab_name,\n                self.original_selected_tab_name,\n                -1,\n            )\n            tab_remaining.update(people_remaining_rows)\n            tab_remaining.format(\"A1:U1\", self.hl_light_blue)\n            # highlight any people in remaining tab at the same address\n            # TODO: do we ever actually hit this code? We should have deleted\n            # all the people who might have been duplicates in selected_remaining_tables()\n            if settings.check_same_address:\n                address_cols: list[int] = [tab_remaining.find(csa).col for csa in settings.check_same_address_columns]  # type: ignore[union-attr]\n                dupes_set: set[int] = set()\n                n = len(people_remaining_rows)\n                for i in range(n):\n                    rowrem1 = people_remaining_rows[i]\n                    for j in range(i + 1, n):\n                        rowrem2 = people_remaining_rows[j]\n                        if rowrem1 != rowrem2 and all(rowrem1[col] == rowrem2[col] for col in address_cols):\n                            dupes_set.add(i + 1)\n                            dupes_set.add(j + 1)\n                dupes = sorted(dupes_set)\n                for i in range(min(30, len(dupes))):\n                    tab_remaining.format(str(dupes[i]), self.hl_orange)\n        return dupes\n\n    def output_multi_selections(\n        self,\n        multi_selections: list[list[str]],\n    ) -&gt; None:\n        assert self.gen_rem_tab == \"off\"\n        tab_original_selected = self._clear_or_create_tab(\n            self.original_selected_tab_name,\n            \"ignoreme\",\n            0,\n        )\n        tab_original_selected.update(multi_selections)\n        tab_original_selected.format(\"A1:U1\", self.hl_light_blue)\n</code></pre>"},{"location":"modules/#sortition_algorithms.adapters.GSheetAdapter.messages","title":"<code>messages()</code>","text":"<p>Return accumulated messages and reset</p> Source code in <code>src/sortition_algorithms/adapters.py</code> <pre><code>def messages(self) -&gt; list[str]:\n    \"\"\"Return accumulated messages and reset\"\"\"\n    messages = self._messages\n    self._messages = []\n    return messages\n</code></pre>"},{"location":"modules/#sortition_algorithms.committee_generation.find_any_committee","title":"<code>find_any_committee(features, people, number_people_wanted, settings)</code>","text":"<p>Find any single feasible committee that satisfies the quotas.</p> <p>Parameters:</p> Name Type Description Default <code>features</code> <code>FeatureCollection</code> <p>FeatureCollection with min/max quotas</p> required <code>people</code> <code>People</code> <p>People object with pool members</p> required <code>number_people_wanted</code> <code>int</code> <p>desired size of the panel</p> required <code>settings</code> <code>Settings</code> <p>Settings object containing configuration</p> required <p>Returns:</p> Type Description <code>tuple[list[frozenset[str]], list[str]]</code> <p>tuple of (list containing one committee as frozenset of person_ids, empty list of messages)</p> <p>Raises:</p> Type Description <code>InfeasibleQuotasError</code> <p>If quotas are infeasible</p> <code>SelectionError</code> <p>If solver fails for other reasons</p> Source code in <code>src/sortition_algorithms/committee_generation.py</code> <pre><code>def find_any_committee(\n    features: FeatureCollection,\n    people: People,\n    number_people_wanted: int,\n    settings: Settings,\n) -&gt; tuple[list[frozenset[str]], list[str]]:\n    \"\"\"Find any single feasible committee that satisfies the quotas.\n\n    Args:\n        features: FeatureCollection with min/max quotas\n        people: People object with pool members\n        number_people_wanted: desired size of the panel\n        settings: Settings object containing configuration\n\n    Returns:\n        tuple of (list containing one committee as frozenset of person_ids, empty list of messages)\n\n    Raises:\n        InfeasibleQuotasError: If quotas are infeasible\n        SelectionError: If solver fails for other reasons\n    \"\"\"\n    model, agent_vars = _setup_committee_generation(features, people, number_people_wanted, settings)\n    committee = _ilp_results_to_committee(agent_vars)\n    return [committee], []\n</code></pre>"},{"location":"modules/#sortition_algorithms.committee_generation.find_distribution_leximin","title":"<code>find_distribution_leximin(features, people, number_people_wanted, settings)</code>","text":"<p>Find a distribution over feasible committees that maximizes the minimum probability of an agent being selected (just like maximin), but breaks ties to maximize the second-lowest probability, breaks further ties to maximize the third-lowest probability and so forth.</p> <p>Parameters:</p> Name Type Description Default <code>features</code> <code>FeatureCollection</code> <p>FeatureCollection with min/max quotas</p> required <code>people</code> <code>People</code> <p>People object with pool members</p> required <code>number_people_wanted</code> <code>int</code> <p>desired size of the panel</p> required <code>settings</code> <code>Settings</code> <p>Settings object containing configuration</p> required <p>Returns:</p> Type Description <code>list[frozenset[str]]</code> <p>tuple of (committees, probabilities, output_lines)</p> <code>list[float]</code> <ul> <li>committees: list of feasible committees (frozenset of agent IDs)</li> </ul> <code>list[str]</code> <ul> <li>probabilities: list of probabilities for each committee</li> </ul> <code>tuple[list[frozenset[str]], list[float], list[str]]</code> <ul> <li>output_lines: list of debug strings</li> </ul> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If Gurobi is not available</p> Source code in <code>src/sortition_algorithms/committee_generation.py</code> <pre><code>def find_distribution_leximin(\n    features: FeatureCollection,\n    people: People,\n    number_people_wanted: int,\n    settings: Settings,\n) -&gt; tuple[list[frozenset[str]], list[float], list[str]]:\n    \"\"\"Find a distribution over feasible committees that maximizes the minimum probability of an agent being selected\n    (just like maximin), but breaks ties to maximize the second-lowest probability, breaks further ties to maximize the\n    third-lowest probability and so forth.\n\n    Args:\n        features: FeatureCollection with min/max quotas\n        people: People object with pool members\n        number_people_wanted: desired size of the panel\n        settings: Settings object containing configuration\n\n    Returns:\n        tuple of (committees, probabilities, output_lines)\n        - committees: list of feasible committees (frozenset of agent IDs)\n        - probabilities: list of probabilities for each committee\n        - output_lines: list of debug strings\n\n    Raises:\n        RuntimeError: If Gurobi is not available\n    \"\"\"\n    if not GUROBI_AVAILABLE:\n        msg = \"Leximin algorithm requires Gurobi solver which is not available\"\n        raise RuntimeError(msg)\n\n    output_lines = [print_ret(\"Using leximin algorithm.\")]\n    grb.setParam(\"OutputFlag\", 0)\n\n    # Set up an ILP that can be used for discovering new feasible committees\n    new_committee_model, agent_vars = _setup_committee_generation(features, people, number_people_wanted, settings)\n\n    # Find initial committees that cover every possible agent\n    committees, covered_agents, initial_output = _generate_initial_committees(\n        new_committee_model, agent_vars, 3 * people.count\n    )\n    output_lines += initial_output\n\n    # Run the main leximin optimization loop to fix agent probabilities\n    fixed_probabilities = _run_leximin_main_loop(new_committee_model, agent_vars, committees, people, output_lines)\n\n    # Convert fixed agent probabilities to committee probabilities\n    probabilities_normalised = _solve_leximin_primal_for_final_probabilities(committees, fixed_probabilities)\n\n    return list(committees), probabilities_normalised, output_lines\n</code></pre>"},{"location":"modules/#sortition_algorithms.committee_generation.find_distribution_maximin","title":"<code>find_distribution_maximin(features, people, number_people_wanted, settings)</code>","text":"<p>Find a distribution over feasible committees that maximizes the minimum probability of an agent being selected.</p> <p>Parameters:</p> Name Type Description Default <code>features</code> <code>FeatureCollection</code> <p>FeatureCollection with min/max quotas</p> required <code>people</code> <code>People</code> <p>People object with pool members</p> required <code>number_people_wanted</code> <code>int</code> <p>desired size of the panel</p> required <code>settings</code> <code>Settings</code> <p>Settings object containing configuration</p> required <p>Returns:</p> Type Description <code>list[frozenset[str]]</code> <p>tuple of (committees, probabilities, output_lines)</p> <code>list[float]</code> <ul> <li>committees: list of feasible committees (frozenset of agent IDs)</li> </ul> <code>list[str]</code> <ul> <li>probabilities: list of probabilities for each committee</li> </ul> <code>tuple[list[frozenset[str]], list[float], list[str]]</code> <ul> <li>output_lines: list of debug strings</li> </ul> Source code in <code>src/sortition_algorithms/committee_generation.py</code> <pre><code>def find_distribution_maximin(\n    features: FeatureCollection,\n    people: People,\n    number_people_wanted: int,\n    settings: Settings,\n) -&gt; tuple[list[frozenset[str]], list[float], list[str]]:\n    \"\"\"Find a distribution over feasible committees that maximizes the minimum probability of an agent being selected.\n\n    Args:\n        features: FeatureCollection with min/max quotas\n        people: People object with pool members\n        number_people_wanted: desired size of the panel\n        settings: Settings object containing configuration\n\n    Returns:\n        tuple of (committees, probabilities, output_lines)\n        - committees: list of feasible committees (frozenset of agent IDs)\n        - probabilities: list of probabilities for each committee\n        - output_lines: list of debug strings\n    \"\"\"\n    output_lines = [print_ret(\"Using maximin algorithm.\")]\n\n    # Set up an ILP that can be used for discovering new feasible committees\n    new_committee_model, agent_vars = _setup_committee_generation(features, people, number_people_wanted, settings)\n\n    # Find initial committees that cover every possible agent\n    committees, covered_agents, initial_output = _generate_initial_committees(\n        new_committee_model, agent_vars, people.count\n    )\n    output_lines += initial_output\n\n    # Set up the incremental LP model for column generation\n    incremental_model, incr_agent_vars, upper_bound_var = _setup_maximin_incremental_model(committees, covered_agents)\n\n    # Run the main optimization loop\n    return _run_maximin_optimization_loop(\n        new_committee_model,\n        agent_vars,\n        incremental_model,\n        incr_agent_vars,\n        upper_bound_var,\n        committees,\n        covered_agents,\n        output_lines,\n    )\n</code></pre>"},{"location":"modules/#sortition_algorithms.committee_generation.find_distribution_nash","title":"<code>find_distribution_nash(features, people, number_people_wanted, settings)</code>","text":"<p>Find a distribution over feasible committees that maximizes the Nash welfare, i.e., the product of selection probabilities over all persons.</p> <p>Parameters:</p> Name Type Description Default <code>features</code> <code>FeatureCollection</code> <p>FeatureCollection with min/max quotas</p> required <code>people</code> <code>People</code> <p>People object with pool members</p> required <code>number_people_wanted</code> <code>int</code> <p>desired size of the panel</p> required <code>settings</code> <code>Settings</code> <p>Settings object containing configuration</p> required <p>Returns:</p> Type Description <code>list[frozenset[str]]</code> <p>tuple of (committees, probabilities, output_lines)</p> <code>list[float]</code> <ul> <li>committees: list of feasible committees (frozenset of agent IDs)</li> </ul> <code>list[str]</code> <ul> <li>probabilities: list of probabilities for each committee</li> </ul> <code>tuple[list[frozenset[str]], list[float], list[str]]</code> <ul> <li>output_lines: list of debug strings</li> </ul> <p>The algorithm maximizes the product of selection probabilities \u03a0\u1d62 p\u1d62 by equivalently maximizing log(\u03a0\u1d62 p\u1d62) = \u03a3\u1d62 log(p\u1d62). If some person i is not included in any feasible committee, their p\u1d62 is 0, and this sum is -\u221e. We maximize \u03a3\u1d62 log(p\u1d62) where i is restricted to range over persons that can possibly be included.</p> Source code in <code>src/sortition_algorithms/committee_generation.py</code> <pre><code>def find_distribution_nash(\n    features: FeatureCollection,\n    people: People,\n    number_people_wanted: int,\n    settings: Settings,\n) -&gt; tuple[list[frozenset[str]], list[float], list[str]]:\n    \"\"\"Find a distribution over feasible committees that maximizes the Nash welfare, i.e., the product of\n    selection probabilities over all persons.\n\n    Args:\n        features: FeatureCollection with min/max quotas\n        people: People object with pool members\n        number_people_wanted: desired size of the panel\n        settings: Settings object containing configuration\n\n    Returns:\n        tuple of (committees, probabilities, output_lines)\n        - committees: list of feasible committees (frozenset of agent IDs)\n        - probabilities: list of probabilities for each committee\n        - output_lines: list of debug strings\n\n    The algorithm maximizes the product of selection probabilities \u03a0\u1d62 p\u1d62 by equivalently maximizing\n    log(\u03a0\u1d62 p\u1d62) = \u03a3\u1d62 log(p\u1d62). If some person i is not included in any feasible committee, their p\u1d62 is 0, and\n    this sum is -\u221e. We maximize \u03a3\u1d62 log(p\u1d62) where i is restricted to range over persons that can possibly be included.\n    \"\"\"\n    output_lines = [print_ret(\"Using Nash algorithm.\")]\n\n    # Set up an ILP used for discovering new feasible committees\n    new_committee_model, agent_vars = _setup_committee_generation(features, people, number_people_wanted, settings)\n\n    # Find initial committees that include every possible agent\n    committee_set, covered_agents, initial_output = _generate_initial_committees(\n        new_committee_model, agent_vars, 2 * people.count\n    )\n    committees = list(committee_set)\n    output_lines += initial_output\n\n    # Map the covered agents to indices in a list for easier matrix representation\n    entitlements, contributes_to_entitlement = _define_entitlements(covered_agents)\n\n    # Run the main Nash welfare optimization loop\n    return _run_nash_optimization_loop(\n        new_committee_model,\n        agent_vars,\n        committees,\n        entitlements,\n        contributes_to_entitlement,\n        covered_agents,\n        number_people_wanted,\n        output_lines,\n    )\n</code></pre>"},{"location":"modules/#sortition_algorithms.committee_generation.standardize_distribution","title":"<code>standardize_distribution(committees, probabilities)</code>","text":"<p>Remove committees with zero probability and renormalize.</p> <p>Parameters:</p> Name Type Description Default <code>committees</code> <code>list[frozenset[str]]</code> <p>list of committees</p> required <code>probabilities</code> <code>list[float]</code> <p>corresponding probabilities</p> required <p>Returns:</p> Type Description <code>tuple[list[frozenset[str]], list[float]]</code> <p>tuple of (filtered_committees, normalized_probabilities)</p> Source code in <code>src/sortition_algorithms/committee_generation.py</code> <pre><code>def standardize_distribution(\n    committees: list[frozenset[str]],\n    probabilities: list[float],\n) -&gt; tuple[list[frozenset[str]], list[float]]:\n    \"\"\"Remove committees with zero probability and renormalize.\n\n    Args:\n        committees: list of committees\n        probabilities: corresponding probabilities\n\n    Returns:\n        tuple of (filtered_committees, normalized_probabilities)\n    \"\"\"\n    assert len(committees) == len(probabilities)\n    new_committees = []\n    new_probabilities = []\n    for committee, prob in zip(committees, probabilities, strict=False):\n        if prob &gt;= EPS2:\n            new_committees.append(committee)\n            new_probabilities.append(prob)\n    prob_sum = sum(new_probabilities)\n    new_probabilities = [prob / prob_sum for prob in new_probabilities]\n    return new_committees, new_probabilities\n</code></pre>"},{"location":"modules/#sortition_algorithms.core.find_random_sample","title":"<code>find_random_sample(features, people, number_people_wanted, settings, selection_algorithm='maximin', test_selection=False, number_selections=1)</code>","text":"<p>Main algorithm to find one or multiple random committees.</p> <p>Parameters:</p> Name Type Description Default <code>features</code> <code>FeatureCollection</code> <p>FeatureCollection with min/max quotas</p> required <code>people</code> <code>People</code> <p>People object with pool members</p> required <code>number_people_wanted</code> <code>int</code> <p>desired size of the panel</p> required <code>settings</code> <code>Settings</code> <p>Settings object containing configuration</p> required <code>selection_algorithm</code> <code>str</code> <p>one of \"legacy\", \"maximin\", \"leximin\", or \"nash\"</p> <code>'maximin'</code> <code>test_selection</code> <code>bool</code> <p>if set, do not do a random selection, but just return some valid panel. Useful for quickly testing whether quotas are satisfiable, but should always be false for actual selection!</p> <code>False</code> <code>number_selections</code> <code>int</code> <p>how many panels to return. Most of the time, this should be set to 1, which means that a single panel is chosen. When specifying a value n \u2265 2, the function will return a list of length n, containing multiple panels (some panels might be repeated in the list). In this case the eventual panel should be drawn uniformly at random from the returned list.</p> <code>1</code> <p>Returns:</p> Type Description <code>list[frozenset[str]]</code> <p>tuple of (committee_lottery, output_lines)</p> <code>list[str]</code> <ul> <li>committee_lottery: list of committees, where each committee is a frozen set of pool member ids</li> </ul> <code>tuple[list[frozenset[str]], list[str]]</code> <ul> <li>output_lines: list of debug strings</li> </ul> <p>Raises:</p> Type Description <code>InfeasibleQuotasError</code> <p>if the quotas cannot be satisfied, which includes a suggestion for how to modify them</p> <code>SelectionError</code> <p>in multiple other failure cases</p> <code>ValueError</code> <p>for invalid parameters</p> <code>RuntimeError</code> <p>if required solver is not available</p> Source code in <code>src/sortition_algorithms/core.py</code> <pre><code>def find_random_sample(\n    features: FeatureCollection,\n    people: People,\n    number_people_wanted: int,\n    settings: Settings,\n    selection_algorithm: str = \"maximin\",\n    test_selection: bool = False,\n    number_selections: int = 1,\n) -&gt; tuple[list[frozenset[str]], list[str]]:\n    \"\"\"Main algorithm to find one or multiple random committees.\n\n    Args:\n        features: FeatureCollection with min/max quotas\n        people: People object with pool members\n        number_people_wanted: desired size of the panel\n        settings: Settings object containing configuration\n        selection_algorithm: one of \"legacy\", \"maximin\", \"leximin\", or \"nash\"\n        test_selection: if set, do not do a random selection, but just return some valid panel.\n            Useful for quickly testing whether quotas are satisfiable, but should always be false for actual selection!\n        number_selections: how many panels to return. Most of the time, this should be set to 1, which means that\n            a single panel is chosen. When specifying a value n \u2265 2, the function will return a list of length n,\n            containing multiple panels (some panels might be repeated in the list). In this case the eventual panel\n            should be drawn uniformly at random from the returned list.\n\n    Returns:\n        tuple of (committee_lottery, output_lines)\n        - committee_lottery: list of committees, where each committee is a frozen set of pool member ids\n        - output_lines: list of debug strings\n\n    Raises:\n        InfeasibleQuotasError: if the quotas cannot be satisfied, which includes a suggestion for how to modify them\n        SelectionError: in multiple other failure cases\n        ValueError: for invalid parameters\n        RuntimeError: if required solver is not available\n    \"\"\"\n    # Input validation\n    if test_selection and number_selections != 1:\n        msg = (\n            \"Running the test selection does not support generating a transparent lottery, so, if \"\n            \"`test_selection` is true, `number_selections` must be 1.\"\n        )\n        raise ValueError(msg)\n\n    if selection_algorithm == \"legacy\" and number_selections != 1:\n        msg = (\n            \"Currently, the legacy algorithm does not support generating a transparent lottery, \"\n            \"so `number_selections` must be set to 1.\"\n        )\n        raise ValueError(msg)\n\n    # Quick test selection using find_any_committee\n    if test_selection:\n        print(\"Running test selection.\")\n        return find_any_committee(features, people, number_people_wanted, settings)\n\n    output_lines = []\n\n    # Check if Gurobi is available for leximin\n    if selection_algorithm == \"leximin\" and not GUROBI_AVAILABLE:\n        output_lines.append(\n            print_ret(\n                \"The leximin algorithm requires the optimization library Gurobi to be installed \"\n                \"(commercial, free academic licenses available). Switching to the simpler \"\n                \"maximin algorithm, which can be run using open source solvers.\"\n            )\n        )\n        selection_algorithm = \"maximin\"\n\n    # Route to appropriate algorithm\n    if selection_algorithm == \"legacy\":\n        # Import here to avoid circular imports\n        from sortition_algorithms.find_sample import find_random_sample_legacy\n\n        return find_random_sample_legacy(\n            people,\n            features,\n            number_people_wanted,\n            settings.check_same_address,\n            settings.check_same_address_columns,\n        )\n    elif selection_algorithm == \"leximin\":\n        committees, probabilities, new_output_lines = find_distribution_leximin(\n            features, people, number_people_wanted, settings\n        )\n    elif selection_algorithm == \"maximin\":\n        committees, probabilities, new_output_lines = find_distribution_maximin(\n            features, people, number_people_wanted, settings\n        )\n    elif selection_algorithm == \"nash\":\n        committees, probabilities, new_output_lines = find_distribution_nash(\n            features, people, number_people_wanted, settings\n        )\n    else:\n        msg = (\n            f\"Unknown selection algorithm {selection_algorithm!r}, must be either 'legacy', 'leximin', \"\n            f\"'maximin', or 'nash'.\"\n        )\n        raise ValueError(msg)\n\n    # Post-process the distribution\n    committees, probabilities = standardize_distribution(committees, probabilities)\n    if len(committees) &gt; people.count:\n        print(\n            \"INFO: The distribution over panels is what is known as a 'basic solution'. There is no reason for concern \"\n            \"about the correctness of your output, but we'd appreciate if you could reach out to panelot\"\n            f\"@paulgoelz.de with the following information: algorithm={selection_algorithm}, \"\n            f\"num_panels={len(committees)}, num_agents={people.count}, min_probs={min(probabilities)}.\"\n        )\n\n    assert len(set(committees)) == len(committees)\n\n    output_lines += new_output_lines\n    output_lines += _distribution_stats(people, committees, probabilities)\n\n    # Convert to lottery\n    committee_lottery = lottery_rounding(committees, probabilities, number_selections)\n\n    return committee_lottery, output_lines\n</code></pre>"},{"location":"modules/#sortition_algorithms.core.lottery_rounding","title":"<code>lottery_rounding(committees, probabilities, number_selections)</code>","text":"<p>Convert probability distribution over committees to a discrete lottery.</p> <p>Parameters:</p> Name Type Description Default <code>committees</code> <code>list[frozenset[str]]</code> <p>list of committees</p> required <code>probabilities</code> <code>list[float]</code> <p>corresponding probabilities (must sum to 1)</p> required <code>number_selections</code> <code>int</code> <p>number of committees to return</p> required <p>Returns:</p> Type Description <code>list[frozenset[str]]</code> <p>list of committees (may contain duplicates) of length number_selections</p> Source code in <code>src/sortition_algorithms/core.py</code> <pre><code>def lottery_rounding(\n    committees: list[frozenset[str]],\n    probabilities: list[float],\n    number_selections: int,\n) -&gt; list[frozenset[str]]:\n    \"\"\"Convert probability distribution over committees to a discrete lottery.\n\n    Args:\n        committees: list of committees\n        probabilities: corresponding probabilities (must sum to 1)\n        number_selections: number of committees to return\n\n    Returns:\n        list of committees (may contain duplicates) of length number_selections\n    \"\"\"\n    assert len(committees) == len(probabilities)\n    assert number_selections &gt;= 1\n\n    num_copies: list[int] = []\n    residuals: list[float] = []\n    for _, prob in zip(committees, probabilities, strict=False):\n        scaled_prob = prob * number_selections\n        num_copies.append(int(scaled_prob))  # give lower quotas\n        residuals.append(scaled_prob - int(scaled_prob))\n\n    rounded_up_indices = pipage_rounding(list(enumerate(residuals)))\n    for committee_index in rounded_up_indices:\n        num_copies[committee_index] += 1\n\n    committee_lottery: list[frozenset[str]] = []\n    for committee, committee_copies in zip(committees, num_copies, strict=False):\n        committee_lottery += [committee for _ in range(committee_copies)]\n\n    return committee_lottery\n</code></pre>"},{"location":"modules/#sortition_algorithms.core.pipage_rounding","title":"<code>pipage_rounding(marginals)</code>","text":"<p>Pipage rounding algorithm for converting fractional solutions to integer solutions.</p> <p>Takes a list of (object, probability) pairs and randomly rounds them to a set of objects such that the expected number of times each object appears equals its probability.</p> <p>Parameters:</p> Name Type Description Default <code>marginals</code> <code>list[tuple[int, float]]</code> <p>list of (object, probability) pairs where probabilities sum to an integer</p> required <p>Returns:</p> Type Description <code>list[int]</code> <p>list of objects that were selected</p> Source code in <code>src/sortition_algorithms/core.py</code> <pre><code>def pipage_rounding(marginals: list[tuple[int, float]]) -&gt; list[int]:\n    \"\"\"Pipage rounding algorithm for converting fractional solutions to integer solutions.\n\n    Takes a list of (object, probability) pairs and randomly rounds them to a set of objects\n    such that the expected number of times each object appears equals its probability.\n\n    Args:\n        marginals: list of (object, probability) pairs where probabilities sum to an integer\n\n    Returns:\n        list of objects that were selected\n    \"\"\"\n    assert all(0.0 &lt;= p &lt;= 1.0 for _, p in marginals)\n\n    outcomes: list[int] = []\n    while True:\n        if len(marginals) == 0:\n            return outcomes\n        if len(marginals) == 1:\n            obj, prob = marginals[0]\n            if random_provider().uniform(0.0, 1.0) &lt; prob:\n                outcomes.append(obj)\n            marginals = []\n        else:\n            obj0, prob0 = marginals[0]\n            if prob0 &gt; 1.0 - EPS2:\n                outcomes.append(obj0)\n                marginals = marginals[1:]\n                continue\n            if prob0 &lt; EPS2:\n                marginals = marginals[1:]\n                continue\n\n            obj1, prob1 = marginals[1]\n            if prob1 &gt; 1.0 - EPS2:\n                outcomes.append(obj1)\n                marginals = [marginals[0]] + marginals[2:]\n                continue\n            if prob1 &lt; EPS2:\n                marginals = [marginals[0]] + marginals[2:]\n                continue\n\n            inc0_dec1_amount = min(\n                1.0 - prob0, prob1\n            )  # maximal amount that prob0 can be increased and prob1 can be decreased\n            dec0_inc1_amount = min(prob0, 1.0 - prob1)\n            choice_probability = dec0_inc1_amount / (inc0_dec1_amount + dec0_inc1_amount)\n\n            if random_provider().uniform(0.0, 1.0) &lt; choice_probability:  # increase prob0 and decrease prob1\n                prob0 += inc0_dec1_amount\n                prob1 -= inc0_dec1_amount\n            else:\n                prob0 -= dec0_inc1_amount\n                prob1 += dec0_inc1_amount\n            marginals = [(obj0, prob0), (obj1, prob1)] + marginals[2:]\n</code></pre>"},{"location":"modules/#sortition_algorithms.core.run_stratification","title":"<code>run_stratification(features, people, number_people_wanted, settings, test_selection=False, number_selections=1)</code>","text":"<p>Run stratified random selection with retry logic.</p> <p>Parameters:</p> Name Type Description Default <code>features</code> <code>FeatureCollection</code> <p>FeatureCollection with min/max quotas for each feature value</p> required <code>people</code> <code>People</code> <p>People object containing the pool of candidates</p> required <code>number_people_wanted</code> <code>int</code> <p>Desired size of the panel</p> required <code>settings</code> <code>Settings</code> <p>Settings object containing configuration</p> required <code>test_selection</code> <code>bool</code> <p>If True, don't randomize (for testing only)</p> <code>False</code> <code>number_selections</code> <code>int</code> <p>Number of panels to return</p> <code>1</code> <p>Returns:</p> Type Description <code>bool</code> <p>Tuple of (success, selected_committees, output_lines)</p> <code>list[frozenset[str]]</code> <ul> <li>success: Whether selection succeeded within max attempts</li> </ul> <code>list[str]</code> <ul> <li>selected_committees: List of committees (frozensets of person IDs)</li> </ul> <code>tuple[bool, list[frozenset[str]], list[str]]</code> <ul> <li>output_lines: Debug and status messages</li> </ul> <p>Raises:</p> Type Description <code>Exception</code> <p>If number_people_wanted is outside valid range for any feature</p> <code>ValueError</code> <p>For invalid parameters</p> <code>RuntimeError</code> <p>If required solver is not available</p> <code>InfeasibleQuotasError</code> <p>If quotas cannot be satisfied</p> Source code in <code>src/sortition_algorithms/core.py</code> <pre><code>def run_stratification(\n    features: FeatureCollection,\n    people: People,\n    number_people_wanted: int,\n    settings: Settings,\n    test_selection: bool = False,\n    number_selections: int = 1,\n) -&gt; tuple[bool, list[frozenset[str]], list[str]]:\n    \"\"\"Run stratified random selection with retry logic.\n\n    Args:\n        features: FeatureCollection with min/max quotas for each feature value\n        people: People object containing the pool of candidates\n        number_people_wanted: Desired size of the panel\n        settings: Settings object containing configuration\n        test_selection: If True, don't randomize (for testing only)\n        number_selections: Number of panels to return\n\n    Returns:\n        Tuple of (success, selected_committees, output_lines)\n        - success: Whether selection succeeded within max attempts\n        - selected_committees: List of committees (frozensets of person IDs)\n        - output_lines: Debug and status messages\n\n    Raises:\n        Exception: If number_people_wanted is outside valid range for any feature\n        ValueError: For invalid parameters\n        RuntimeError: If required solver is not available\n        InfeasibleQuotasError: If quotas cannot be satisfied\n    \"\"\"\n    # Check if desired number is within feature constraints\n    features.check_desired(number_people_wanted)\n\n    # Set random seed if specified\n    # If the seed is zero or None, we use the secrets module, as it is better\n    # from a security point of view\n    set_random_provider(settings.random_number_seed)\n\n    success = False\n    output_lines = []\n\n    if test_selection:\n        output_lines.append(\n            \"&lt;b style='color: red'&gt;WARNING: Panel is not selected at random! Only use for testing!&lt;/b&gt;&lt;br&gt;\",\n        )\n\n    output_lines.append(\"&lt;b&gt;Initial: (selected = 0)&lt;/b&gt;\")\n    output_lines += _initial_print_category_info(\n        features,\n        people,\n    )\n    people_selected: list[frozenset[str]] = []\n\n    tries = 0\n    for tries in range(settings.max_attempts):\n        people_selected = []\n\n        output_lines.append(f\"&lt;b&gt;Trial number: {tries}&lt;/b&gt;\")\n\n        try:\n            people_selected, new_output_lines = find_random_sample(\n                features,\n                people,\n                number_people_wanted,\n                settings,\n                settings.selection_algorithm,\n                test_selection,\n                number_selections,\n            )\n            output_lines += new_output_lines\n\n            # Check if targets were met (only works for number_selections = 1)\n            new_output_lines = _print_category_info(\n                features,\n                people,\n                people_selected,\n                number_people_wanted,\n            )\n            success, check_output_lines = _check_category_selected(\n                features,\n                people,\n                people_selected,\n                number_selections,\n            )\n\n            if success:\n                output_lines.append(\"&lt;b&gt;SUCCESS!!&lt;/b&gt; Final:\")\n                output_lines += new_output_lines + check_output_lines\n                break\n\n        except (ValueError, RuntimeError) as err:\n            output_lines.append(str(err))\n            break\n        except errors.InfeasibleQuotasError as err:\n            output_lines += err.output\n            break\n        except errors.SelectionError as serr:\n            output_lines.append(f\"Failed: Selection Error thrown: {serr}\")\n\n    if not success:\n        output_lines.append(f\"Failed {tries} times... gave up.\")\n\n    return success, people_selected, output_lines\n</code></pre>"},{"location":"modules/#sortition_algorithms.core.selected_remaining_tables","title":"<code>selected_remaining_tables(full_people, people_selected, features, settings)</code>","text":"<p>write some text</p> <p>people_selected is a single frozenset[str] - it must be unwrapped before being passed to this function.</p> Source code in <code>src/sortition_algorithms/core.py</code> <pre><code>def selected_remaining_tables(\n    full_people: People,\n    people_selected: frozenset[str],\n    features: FeatureCollection,\n    settings: Settings,\n) -&gt; tuple[list[list[str]], list[list[str]], list[str]]:\n    \"\"\"\n    write some text\n\n    people_selected is a single frozenset[str] - it must be unwrapped before being passed\n    to this function.\n    \"\"\"\n    people_working = deepcopy(full_people)\n    output_lines: list[str] = []\n\n    people_selected_rows = person_list_to_table(people_selected, people_working, features, settings)\n\n    # now delete the selected people (and maybe also those at the same address)\n    num_same_address_deleted = 0\n    for pkey in people_selected:\n        # if check address then delete all those at this address (will NOT delete the one we want as well)\n        if settings.check_same_address:\n            pkey_to_delete = list(people_working.matching_address(pkey, settings.check_same_address_columns))\n            num_same_address_deleted += len(pkey_to_delete) + 1\n            # then delete this/these people at the same address from the reserve/remaining pool\n            people_working.remove_many([pkey, *pkey_to_delete])\n        else:\n            people_working.remove(pkey)\n\n    # add the columns to keep into remaining people\n    # as above all these values are all in people_working but this is tidier...\n    people_remaining_rows = person_list_to_table(people_working, people_working, features, settings)\n    return people_selected_rows, people_remaining_rows, output_lines\n\n    # TODO: put this code somewhere more suitable\n    # maybe in strat app only?\n    \"\"\"\n    dupes = self._output_selected_remaining(\n        settings,\n        people_selected_rows,\n        people_remaining_rows,\n    )\n    if settings.check_same_address and self.gen_rem_tab == \"on\":\n        output_lines.append(\n            f\"Deleted {num_same_address_deleted} people from remaining file who had the same \"\n            f\"address as selected people.\",\n        )\n        m = min(30, len(dupes))\n        output_lines.append(\n            f\"In the remaining tab there are {len(dupes)} people who share the same address as \"\n            f\"someone else in the tab. We highlighted the first {m} of these. \"\n            f\"The full list of lines is {dupes}\",\n        )\n    \"\"\"\n</code></pre>"},{"location":"modules/#sortition_algorithms.features.FeatureCollection","title":"<code>FeatureCollection</code>","text":"<p>A full set of features for a stratification.</p> <p>The keys here are the names of the features. They could be: gender, age_bracket, education_level etc</p> <p>The values are FeatureValues objects - the breakdown of the values for a feature.</p> Source code in <code>src/sortition_algorithms/features.py</code> <pre><code>class FeatureCollection:\n    \"\"\"\n    A full set of features for a stratification.\n\n    The keys here are the names of the features. They could be: gender, age_bracket, education_level etc\n\n    The values are FeatureValues objects - the breakdown of the values for a feature.\n    \"\"\"\n\n    # TODO: consider splitting the updates/remaining into a parallel set of classes\n    # then this can just have targets, and the running totals can be in classes we can\n    # regenerate now and then\n\n    def __init__(self) -&gt; None:\n        self.collection: dict[str, FeatureValues] = defaultdict(FeatureValues)\n\n    def __eq__(self, other: Any) -&gt; bool:\n        if not isinstance(other, self.__class__):\n            return False\n        return self.collection == other.collection\n\n    def add_feature(self, feature_name: str, value_name: str, fv_counts: FeatureValueCounts) -&gt; None:\n        self.collection[feature_name].add_value_counts(value_name, fv_counts)\n\n    @property\n    def feature_names(self) -&gt; list[str]:\n        return list(self.collection.keys())\n\n    def feature_values(self) -&gt; Iterator[tuple[str, list[str]]]:\n        for feature_name, feature_value in self.collection.items():\n            yield feature_name, feature_value.values\n\n    def feature_values_counts(self) -&gt; Iterator[tuple[str, str, FeatureValueCounts]]:\n        for feature_name, feature_values in self.collection.items():\n            for value, value_counts in feature_values.values_counts():\n                yield feature_name, value, value_counts\n\n    def _safe_max_flex_val(self) -&gt; int:\n        if not self.collection:\n            return 0\n        # to avoid errors, if max_flex is not set we must set it at least as high as the highest\n        return max(v.maximum_selection() for v in self.collection.values())\n\n    def set_default_max_flex(self) -&gt; None:\n        \"\"\"Note this only sets it if left at the default value\"\"\"\n        max_flex = self._safe_max_flex_val()\n        for feature_values in self.collection.values():\n            feature_values.set_default_max_flex(max_flex)\n\n    def add_remaining(self, feature: str, value_name: str) -&gt; None:\n        self.collection[feature].add_remaining(value_name)\n\n    def add_selected(self, feature: str, value_name: str) -&gt; None:\n        self.collection[feature].add_selected(value_name)\n\n    def remove_remaining(self, feature: str, value_name: str) -&gt; None:\n        try:\n            self.collection[feature].remove_remaining(value_name)\n        except errors.SelectionError as e:\n            msg = f\"Failed removing from {feature}/{value_name}: {e}\"\n            raise errors.SelectionError(msg) from None\n\n    def minimum_selection(self) -&gt; int:\n        \"\"\"\n        The minimum selection for this set of features is the largest minimum selection\n        of any individual feature.\n        \"\"\"\n        if not self.collection:\n            return 0\n        return max(v.minimum_selection() for v in self.collection.values())\n\n    def maximum_selection(self) -&gt; int:\n        \"\"\"\n        The maximum selection for this set of features is the smallest maximum selection\n        of any individual feature.\n        \"\"\"\n        if not self.collection:\n            return 0\n        return min(v.maximum_selection() for v in self.collection.values())\n\n    def check_min_max(self) -&gt; None:\n        \"\"\"\n        If the min is bigger than the max we're in trouble i.e. there's an input error\n        \"\"\"\n        if self.minimum_selection() &gt; self.maximum_selection():\n            msg = (\n                \"Inconsistent numbers in min and max in the features input: the sum \"\n                \"of the minimum values of a features is larger than the sum of the \"\n                \"maximum values of a(nother) feature. \"\n            )\n            raise ValueError(msg)\n\n    def check_desired(self, desired_number: int) -&gt; None:\n        \"\"\"\n        Check if the desired number of people is within the min/max of every feature.\n        \"\"\"\n        for feature_name, feature_values in self.collection.items():\n            if (\n                desired_number &lt; feature_values.minimum_selection()\n                or desired_number &gt; feature_values.maximum_selection()\n            ):\n                msg = (\n                    f\"The number of people to select ({desired_number}) is out of the range of \"\n                    f\"the numbers of people in the {feature_name} feature. It should be within \"\n                    f\"[{feature_values.minimum_selection()}, {feature_values.maximum_selection()}].\"\n                )\n                raise Exception(msg)\n</code></pre>"},{"location":"modules/#sortition_algorithms.features.FeatureCollection.check_desired","title":"<code>check_desired(desired_number)</code>","text":"<p>Check if the desired number of people is within the min/max of every feature.</p> Source code in <code>src/sortition_algorithms/features.py</code> <pre><code>def check_desired(self, desired_number: int) -&gt; None:\n    \"\"\"\n    Check if the desired number of people is within the min/max of every feature.\n    \"\"\"\n    for feature_name, feature_values in self.collection.items():\n        if (\n            desired_number &lt; feature_values.minimum_selection()\n            or desired_number &gt; feature_values.maximum_selection()\n        ):\n            msg = (\n                f\"The number of people to select ({desired_number}) is out of the range of \"\n                f\"the numbers of people in the {feature_name} feature. It should be within \"\n                f\"[{feature_values.minimum_selection()}, {feature_values.maximum_selection()}].\"\n            )\n            raise Exception(msg)\n</code></pre>"},{"location":"modules/#sortition_algorithms.features.FeatureCollection.check_min_max","title":"<code>check_min_max()</code>","text":"<p>If the min is bigger than the max we're in trouble i.e. there's an input error</p> Source code in <code>src/sortition_algorithms/features.py</code> <pre><code>def check_min_max(self) -&gt; None:\n    \"\"\"\n    If the min is bigger than the max we're in trouble i.e. there's an input error\n    \"\"\"\n    if self.minimum_selection() &gt; self.maximum_selection():\n        msg = (\n            \"Inconsistent numbers in min and max in the features input: the sum \"\n            \"of the minimum values of a features is larger than the sum of the \"\n            \"maximum values of a(nother) feature. \"\n        )\n        raise ValueError(msg)\n</code></pre>"},{"location":"modules/#sortition_algorithms.features.FeatureCollection.maximum_selection","title":"<code>maximum_selection()</code>","text":"<p>The maximum selection for this set of features is the smallest maximum selection of any individual feature.</p> Source code in <code>src/sortition_algorithms/features.py</code> <pre><code>def maximum_selection(self) -&gt; int:\n    \"\"\"\n    The maximum selection for this set of features is the smallest maximum selection\n    of any individual feature.\n    \"\"\"\n    if not self.collection:\n        return 0\n    return min(v.maximum_selection() for v in self.collection.values())\n</code></pre>"},{"location":"modules/#sortition_algorithms.features.FeatureCollection.minimum_selection","title":"<code>minimum_selection()</code>","text":"<p>The minimum selection for this set of features is the largest minimum selection of any individual feature.</p> Source code in <code>src/sortition_algorithms/features.py</code> <pre><code>def minimum_selection(self) -&gt; int:\n    \"\"\"\n    The minimum selection for this set of features is the largest minimum selection\n    of any individual feature.\n    \"\"\"\n    if not self.collection:\n        return 0\n    return max(v.minimum_selection() for v in self.collection.values())\n</code></pre>"},{"location":"modules/#sortition_algorithms.features.FeatureCollection.set_default_max_flex","title":"<code>set_default_max_flex()</code>","text":"<p>Note this only sets it if left at the default value</p> Source code in <code>src/sortition_algorithms/features.py</code> <pre><code>def set_default_max_flex(self) -&gt; None:\n    \"\"\"Note this only sets it if left at the default value\"\"\"\n    max_flex = self._safe_max_flex_val()\n    for feature_values in self.collection.values():\n        feature_values.set_default_max_flex(max_flex)\n</code></pre>"},{"location":"modules/#sortition_algorithms.features.FeatureValues","title":"<code>FeatureValues</code>","text":"<p>A full set of values for a single feature.</p> <p>If the feature is gender, the values could be: male, female, non_binary_other</p> <p>The values are FeatureValueCounts objects - the min, max and current counts of the selected people in that feature value.</p> Source code in <code>src/sortition_algorithms/features.py</code> <pre><code>class FeatureValues:\n    \"\"\"\n    A full set of values for a single feature.\n\n    If the feature is gender, the values could be: male, female, non_binary_other\n\n    The values are FeatureValueCounts objects - the min, max and current counts of the\n    selected people in that feature value.\n    \"\"\"\n\n    def __init__(self) -&gt; None:\n        self.feature_values: dict[str, FeatureValueCounts] = {}\n\n    def __eq__(self, other: Any) -&gt; bool:\n        if not isinstance(other, self.__class__):\n            return False\n        return self.feature_values == other.feature_values\n\n    def add_value_counts(self, value_name: str, fv_counts: FeatureValueCounts) -&gt; None:\n        self.feature_values[value_name] = fv_counts\n\n    def set_default_max_flex(self, max_flex: int) -&gt; None:\n        \"\"\"Note this only sets it if left at the default value\"\"\"\n        for fv_counts in self.feature_values.values():\n            fv_counts.set_default_max_flex(max_flex)\n\n    @property\n    def values(self) -&gt; list[str]:\n        return list(self.feature_values.keys())\n\n    def values_counts(self) -&gt; Iterator[tuple[str, FeatureValueCounts]]:\n        yield from self.feature_values.items()\n\n    def add_remaining(self, value_name: str) -&gt; None:\n        self.feature_values[value_name].add_remaining()\n\n    def add_selected(self, value_name: str) -&gt; None:\n        self.feature_values[value_name].add_selected()\n\n    def remove_remaining(self, value_name: str) -&gt; None:\n        self.feature_values[value_name].remove_remaining()\n\n    def minimum_selection(self) -&gt; int:\n        \"\"\"\n        For this feature, we have to select at least the sum of the minimum of each value\n        \"\"\"\n        return sum(c.min for c in self.feature_values.values())\n\n    def maximum_selection(self) -&gt; int:\n        \"\"\"\n        For this feature, we have to select at most the sum of the maximum of each value\n        \"\"\"\n        return sum(c.max for c in self.feature_values.values())\n</code></pre>"},{"location":"modules/#sortition_algorithms.features.FeatureValues.maximum_selection","title":"<code>maximum_selection()</code>","text":"<p>For this feature, we have to select at most the sum of the maximum of each value</p> Source code in <code>src/sortition_algorithms/features.py</code> <pre><code>def maximum_selection(self) -&gt; int:\n    \"\"\"\n    For this feature, we have to select at most the sum of the maximum of each value\n    \"\"\"\n    return sum(c.max for c in self.feature_values.values())\n</code></pre>"},{"location":"modules/#sortition_algorithms.features.FeatureValues.minimum_selection","title":"<code>minimum_selection()</code>","text":"<p>For this feature, we have to select at least the sum of the minimum of each value</p> Source code in <code>src/sortition_algorithms/features.py</code> <pre><code>def minimum_selection(self) -&gt; int:\n    \"\"\"\n    For this feature, we have to select at least the sum of the minimum of each value\n    \"\"\"\n    return sum(c.min for c in self.feature_values.values())\n</code></pre>"},{"location":"modules/#sortition_algorithms.features.FeatureValues.set_default_max_flex","title":"<code>set_default_max_flex(max_flex)</code>","text":"<p>Note this only sets it if left at the default value</p> Source code in <code>src/sortition_algorithms/features.py</code> <pre><code>def set_default_max_flex(self, max_flex: int) -&gt; None:\n    \"\"\"Note this only sets it if left at the default value\"\"\"\n    for fv_counts in self.feature_values.values():\n        fv_counts.set_default_max_flex(max_flex)\n</code></pre>"},{"location":"modules/#sortition_algorithms.features.read_in_features","title":"<code>read_in_features(features_head, features_body)</code>","text":"<p>Read in stratified selection features and values</p> <p>Note we do want features_head to ensure we don't have multiple columns with the same name</p> Source code in <code>src/sortition_algorithms/features.py</code> <pre><code>def read_in_features(\n    features_head: Iterable[str], features_body: Iterable[dict[str, str]]\n) -&gt; tuple[FeatureCollection, list[str]]:\n    \"\"\"\n    Read in stratified selection features and values\n\n    Note we do want features_head to ensure we don't have multiple columns with the same name\n    \"\"\"\n    features = FeatureCollection()\n    msg: list[str] = []\n    features_flex, filtered_headers = _feature_headers_flex(list(features_head))\n    for row in features_body:\n        # check the set of keys in the row are the same as the headers\n        assert set(filtered_headers) &lt;= set(row.keys())\n        stripped_row = utils.StrippedDict(_normalise_col_names(row))\n        if not stripped_row[\"feature\"]:\n            continue\n        features.add_feature(*_clean_row(stripped_row, features_flex))\n\n    msg.append(f\"Number of features: {len(features.feature_names)}\")\n    features.check_min_max()\n    # check feature_flex to see if we need to set the max here\n    # this only changes the max_flex value if these (optional) flex values are NOT set already\n    features.set_default_max_flex()\n    return features, msg\n</code></pre>"},{"location":"modules/#sortition_algorithms.find_sample.find_random_sample_legacy","title":"<code>find_random_sample_legacy(people, features, number_people_wanted, check_same_address=False, check_same_address_columns=None)</code>","text":"<p>Legacy stratified random selection algorithm.</p> <p>Implements the original algorithm that uses greedy selection based on priority ratios. Always selects from the most urgently needed category first (highest ratio of (min-selected)/remaining), then randomly picks within that category.</p> <p>Parameters:</p> Name Type Description Default <code>people</code> <code>People</code> <p>People collection</p> required <code>features</code> <code>FeatureCollection</code> <p>Feature definitions with min/max targets</p> required <code>number_people_wanted</code> <code>int</code> <p>Number of people to select</p> required <code>check_same_address</code> <code>bool</code> <p>Whether to remove household members when selecting someone</p> <code>False</code> <code>check_same_address_columns</code> <code>list[str] | None</code> <p>Address columns for household identification</p> <code>None</code> <p>Returns:</p> Type Description <code>list[frozenset[str]]</code> <p>Tuple of (selected_committees, output_messages) where:</p> <code>list[str]</code> <ul> <li>selected_committees: List containing one frozenset of selected person IDs</li> </ul> <code>tuple[list[frozenset[str]], list[str]]</code> <ul> <li>output_messages: List of log messages about the selection process</li> </ul> <p>Raises:</p> Type Description <code>SelectionError</code> <p>If selection becomes impossible (not enough people, etc.)</p> Source code in <code>src/sortition_algorithms/find_sample.py</code> <pre><code>def find_random_sample_legacy(\n    people: People,\n    features: FeatureCollection,\n    number_people_wanted: int,\n    check_same_address: bool = False,\n    check_same_address_columns: list[str] | None = None,\n) -&gt; tuple[list[frozenset[str]], list[str]]:\n    \"\"\"\n    Legacy stratified random selection algorithm.\n\n    Implements the original algorithm that uses greedy selection based on priority ratios.\n    Always selects from the most urgently needed category first (highest ratio of\n    (min-selected)/remaining), then randomly picks within that category.\n\n    Args:\n        people: People collection\n        features: Feature definitions with min/max targets\n        number_people_wanted: Number of people to select\n        check_same_address: Whether to remove household members when selecting someone\n        check_same_address_columns: Address columns for household identification\n\n    Returns:\n        Tuple of (selected_committees, output_messages) where:\n        - selected_committees: List containing one frozenset of selected person IDs\n        - output_messages: List of log messages about the selection process\n\n    Raises:\n        SelectionError: If selection becomes impossible (not enough people, etc.)\n    \"\"\"\n    output_lines = [\"Using legacy algorithm.\"]\n    people_selected: set[str] = set()\n\n    # Create PeopleFeatures and initialize\n    people_features = PeopleFeatures(people, features, check_same_address, check_same_address_columns or [])\n    people_features.update_all_features_remaining()\n    people_features.prune_for_feature_max_0()\n\n    # Main selection loop\n    for count in range(number_people_wanted):\n        # Find the category with highest priority ratio\n        try:\n            ratio_result = people_features.find_max_ratio_category()\n        except errors.SelectionError as e:\n            msg = f\"Selection failed on iteration {count + 1}: {e}\"\n            raise errors.SelectionError(msg) from e\n\n        # Find the randomly selected person within that category\n        target_feature = ratio_result.feature_name\n        target_value = ratio_result.feature_value\n        random_position = ratio_result.random_person_index\n\n        selected_person_key = people_features.people.find_person_by_position_in_category(\n            target_feature, target_value, random_position\n        )\n\n        # Should never select the same person twice\n        assert selected_person_key not in people_selected, f\"Person {selected_person_key} was already selected\"\n\n        # Select the person (this also removes household members if configured)\n        people_selected.add(selected_person_key)\n        selected_person_data = people_features.people.get_person_dict(selected_person_key)\n        household_members_removed = people_features.select_person(selected_person_key)\n\n        # Add output messages about household member removal\n        if household_members_removed:\n            output_lines.append(\n                f\"Selected {selected_person_key}, also removed household members: \"\n                f\"{', '.join(household_members_removed)}\"\n            )\n\n        # Handle any categories that are now full after this selection\n        try:\n            category_messages = people_features.handle_category_full_deletions(selected_person_data)\n            output_lines.extend(category_messages)\n        except errors.SelectionError as e:\n            msg = f\"Selection failed after selecting {selected_person_key}: {e}\"\n            raise errors.SelectionError(msg) from e\n\n        # Check if we're about to run out of people (but not on the last iteration)\n        if count &lt; (number_people_wanted - 1) and people_features.people.count == 0:\n            msg = \"Selection failed: Ran out of people before completing selection\"\n            raise errors.SelectionError(msg)\n\n    # Return in legacy format: list containing single frozenset\n    return [frozenset(people_selected)], output_lines\n</code></pre>"},{"location":"modules/#sortition_algorithms.people_features.MaxRatioResult","title":"<code>MaxRatioResult</code>","text":"<p>Result from finding the category with maximum selection ratio.</p> Source code in <code>src/sortition_algorithms/people_features.py</code> <pre><code>@define(kw_only=True, slots=True)\nclass MaxRatioResult:\n    \"\"\"Result from finding the category with maximum selection ratio.\"\"\"\n\n    feature_name: str\n    feature_value: str\n    random_person_index: int\n</code></pre>"},{"location":"modules/#sortition_algorithms.people_features.PeopleFeatures","title":"<code>PeopleFeatures</code>","text":"<p>This class manipulates people and features together, making a deepcopy on init.</p> Source code in <code>src/sortition_algorithms/people_features.py</code> <pre><code>class PeopleFeatures:\n    \"\"\"\n    This class manipulates people and features together, making a deepcopy on init.\n    \"\"\"\n\n    # TODO: consider naming: maybe SelectionState\n\n    def __init__(\n        self,\n        people: People,\n        features: FeatureCollection,\n        check_same_address: bool = False,\n        check_same_address_columns: list[str] | None = None,\n    ) -&gt; None:\n        self.people = deepcopy(people)\n        self.features = deepcopy(features)\n        self.check_same_address = check_same_address\n        self.check_same_address_columns = check_same_address_columns or []\n\n    def update_features_remaining(self, person_key: str) -&gt; None:\n        # this will blow up if the person does not exist\n        person = self.people.get_person_dict(person_key)\n        for feature_name in self.features.feature_names:\n            self.features.add_remaining(feature_name, person[feature_name])\n\n    def update_all_features_remaining(self) -&gt; None:\n        for person_key in self.people:\n            self.update_features_remaining(person_key)\n\n    def delete_all_with_feature_value(self, feature_name: str, feature_value: str) -&gt; tuple[int, int]:\n        \"\"\"\n        When a feature/value is \"full\" we delete everyone else in it.\n        \"Full\" means that the number selected equals the \"max\" amount - that\n        is detected elsewhere and then this method is called.\n        Returns count of those deleted, and count of those left\n        \"\"\"\n        # when a category is full we want to delete everyone in it\n        people_to_delete: list[str] = []\n        for pkey, person in self.people.items():\n            if person[feature_name] == feature_value:\n                people_to_delete.append(pkey)\n                for feature in self.features.feature_names:\n                    try:\n                        self.features.remove_remaining(feature, person[feature])\n                    except errors.SelectionError as e:\n                        msg = (\n                            f\"SELECTION IMPOSSIBLE: FAIL in delete_all_in_feature_value() \"\n                            f\"as after previous deletion no one/not enough left in {feature} \"\n                            f\"{person[feature]}. Tried to delete: {len(people_to_delete)}\"\n                        )\n                        raise errors.SelectionError(msg) from e\n\n        self.people.remove_many(people_to_delete)\n        # return the number of people deleted and the number of people left\n        return len(people_to_delete), self.people.count\n\n    def prune_for_feature_max_0(self) -&gt; list[str]:\n        \"\"\"\n        Check if any feature_value.max is set to zero. if so delete everyone with that feature value\n        NOT DONE: could then check if anyone is left.\n        \"\"\"\n        # TODO: when do we want to do this?\n        msg: list[str] = []\n        msg.append(f\"Number of people: {self.people.count}.\")\n        total_num_deleted = 0\n        for (\n            feature_name,\n            feature_value,\n            fv_counts,\n        ) in self.features.feature_values_counts():\n            if fv_counts.max == 0:  # we don't want any of these people\n                # pass the message in as deleting them might throw an exception\n                msg.append(f\"Feature/value {feature_name}/{feature_value} full - deleting people...\")\n                num_deleted, num_left = self.delete_all_with_feature_value(feature_name, feature_value)\n                # if no exception was thrown above add this bit to the end of the previous message\n                msg[-1] += f\" Deleted {num_deleted}, {num_left} left.\"\n                total_num_deleted += num_deleted\n        # if the total number of people deleted is lots then we're probably doing a replacement selection, which means\n        # the 'remaining' file will be useless - remind the user of this!\n        if total_num_deleted &gt;= self.people.count / 2:\n            msg.append(\n                \"&gt;&gt;&gt; WARNING &lt;&lt;&lt; That deleted MANY PEOPLE - are you doing a \"\n                \"replacement? If so your REMAINING FILE WILL BE USELESS!!!\"\n            )\n        return msg\n\n    def select_person(self, person_key: str) -&gt; list[str]:\n        \"\"\"\n        Selecting a person means:\n        - remove the person from our copy of People\n        - update the `selected` and `remaining` counts of the FeatureCollection\n        - if check_same_address is True, also remove household members (without adding to selected)\n\n        Returns:\n            List of additional people removed due to same address (empty if check_same_address is False)\n        \"\"\"\n        # First, find household members if address checking is enabled (before removing the person)\n        household_members_removed = []\n        if self.check_same_address and self.check_same_address_columns:\n            household_members_removed = list(self.people.matching_address(person_key, self.check_same_address_columns))\n\n        # Handle the main person selection\n        person = self.people.get_person_dict(person_key)\n        for feature in self.features.feature_names:\n            self.features.remove_remaining(feature, person[feature])\n            self.features.add_selected(feature, person[feature])\n        self.people.remove(person_key)\n\n        # Then remove household members if any were found\n        for household_member_key in household_members_removed:\n            household_member = self.people.get_person_dict(household_member_key)\n            for feature in self.features.feature_names:\n                self.features.remove_remaining(feature, household_member[feature])\n                # Note: we don't call add_selected() for household members\n            self.people.remove(household_member_key)\n\n        return household_members_removed\n\n    def find_max_ratio_category(self) -&gt; MaxRatioResult:\n        \"\"\"\n        Find the feature/value combination with the highest selection ratio.\n\n        The ratio is calculated as: (min - selected) / remaining\n        This represents how urgently we need people from this category.\n        Higher ratio = more urgent need (fewer people available relative to what we still need).\n\n        Returns:\n            MaxRatioResult containing the feature name, value, and a random person index\n\n        Raises:\n            SelectionError: If insufficient people remain to meet minimum requirements\n        \"\"\"\n        max_ratio = -100.0\n        result_feature_name = \"\"\n        result_feature_value = \"\"\n        random_person_index = -1\n\n        for (\n            feature_name,\n            feature_value,\n            fv_counts,\n        ) in self.features.feature_values_counts():\n            # Check if we have insufficient people to meet minimum requirements\n            people_still_needed = fv_counts.min - fv_counts.selected\n            if fv_counts.selected &lt; fv_counts.min and fv_counts.remaining &lt; people_still_needed:\n                msg = (\n                    f\"SELECTION IMPOSSIBLE: Not enough people remaining in {feature_name}/{feature_value}. \"\n                    f\"Need {people_still_needed} more, but only {fv_counts.remaining} remaining.\"\n                )\n                raise errors.SelectionError(msg)\n\n            # Skip categories with no remaining people or max = 0\n            if fv_counts.remaining == 0 or fv_counts.max == 0:\n                continue\n\n            # Calculate the priority ratio\n            ratio = people_still_needed / float(fv_counts.remaining)\n\n            # Track the highest ratio category\n            if ratio &gt; max_ratio:\n                max_ratio = ratio\n                result_feature_name = feature_name\n                result_feature_value = feature_value\n                # from 1 to remaining\n                random_person_index = random_provider().randbelow(fv_counts.remaining) + 1\n\n        # If no valid category found, all categories must be at their max or have max=0\n        if not result_feature_name:\n            msg = \"No valid categories found - all may be at maximum or have max=0\"\n            raise errors.SelectionError(msg)\n\n        return MaxRatioResult(\n            feature_name=result_feature_name,\n            feature_value=result_feature_value,\n            random_person_index=random_person_index,\n        )\n\n    def handle_category_full_deletions(self, selected_person_data: dict[str, str]) -&gt; list[str]:\n        \"\"\"\n        Check if any categories are now full after a selection and delete remaining people.\n\n        When a person is selected, some categories may reach their maximum quota.\n        This method identifies such categories and removes all remaining people from them.\n\n        Args:\n            selected_person_data: Dictionary of the selected person's feature values\n\n        Returns:\n            List of output messages about categories that became full and people deleted\n\n        Raises:\n            SelectionError: If deletions would violate minimum constraints\n        \"\"\"\n        output_messages = []\n\n        for (\n            feature_name,\n            feature_value,\n            fv_counts,\n        ) in self.features.feature_values_counts():\n            if feature_value == selected_person_data[feature_name] and fv_counts.selected == fv_counts.max:\n                num_deleted, num_left = self.delete_all_with_feature_value(feature_name, feature_value)\n                if num_deleted &gt; 0:\n                    output_messages.append(\n                        f\"Category {feature_name}/{feature_value} full - deleted {num_deleted} people, {num_left} left.\"\n                    )\n\n        return output_messages\n</code></pre>"},{"location":"modules/#sortition_algorithms.people_features.PeopleFeatures.delete_all_with_feature_value","title":"<code>delete_all_with_feature_value(feature_name, feature_value)</code>","text":"<p>When a feature/value is \"full\" we delete everyone else in it. \"Full\" means that the number selected equals the \"max\" amount - that is detected elsewhere and then this method is called. Returns count of those deleted, and count of those left</p> Source code in <code>src/sortition_algorithms/people_features.py</code> <pre><code>def delete_all_with_feature_value(self, feature_name: str, feature_value: str) -&gt; tuple[int, int]:\n    \"\"\"\n    When a feature/value is \"full\" we delete everyone else in it.\n    \"Full\" means that the number selected equals the \"max\" amount - that\n    is detected elsewhere and then this method is called.\n    Returns count of those deleted, and count of those left\n    \"\"\"\n    # when a category is full we want to delete everyone in it\n    people_to_delete: list[str] = []\n    for pkey, person in self.people.items():\n        if person[feature_name] == feature_value:\n            people_to_delete.append(pkey)\n            for feature in self.features.feature_names:\n                try:\n                    self.features.remove_remaining(feature, person[feature])\n                except errors.SelectionError as e:\n                    msg = (\n                        f\"SELECTION IMPOSSIBLE: FAIL in delete_all_in_feature_value() \"\n                        f\"as after previous deletion no one/not enough left in {feature} \"\n                        f\"{person[feature]}. Tried to delete: {len(people_to_delete)}\"\n                    )\n                    raise errors.SelectionError(msg) from e\n\n    self.people.remove_many(people_to_delete)\n    # return the number of people deleted and the number of people left\n    return len(people_to_delete), self.people.count\n</code></pre>"},{"location":"modules/#sortition_algorithms.people_features.PeopleFeatures.find_max_ratio_category","title":"<code>find_max_ratio_category()</code>","text":"<p>Find the feature/value combination with the highest selection ratio.</p> <p>The ratio is calculated as: (min - selected) / remaining This represents how urgently we need people from this category. Higher ratio = more urgent need (fewer people available relative to what we still need).</p> <p>Returns:</p> Type Description <code>MaxRatioResult</code> <p>MaxRatioResult containing the feature name, value, and a random person index</p> <p>Raises:</p> Type Description <code>SelectionError</code> <p>If insufficient people remain to meet minimum requirements</p> Source code in <code>src/sortition_algorithms/people_features.py</code> <pre><code>def find_max_ratio_category(self) -&gt; MaxRatioResult:\n    \"\"\"\n    Find the feature/value combination with the highest selection ratio.\n\n    The ratio is calculated as: (min - selected) / remaining\n    This represents how urgently we need people from this category.\n    Higher ratio = more urgent need (fewer people available relative to what we still need).\n\n    Returns:\n        MaxRatioResult containing the feature name, value, and a random person index\n\n    Raises:\n        SelectionError: If insufficient people remain to meet minimum requirements\n    \"\"\"\n    max_ratio = -100.0\n    result_feature_name = \"\"\n    result_feature_value = \"\"\n    random_person_index = -1\n\n    for (\n        feature_name,\n        feature_value,\n        fv_counts,\n    ) in self.features.feature_values_counts():\n        # Check if we have insufficient people to meet minimum requirements\n        people_still_needed = fv_counts.min - fv_counts.selected\n        if fv_counts.selected &lt; fv_counts.min and fv_counts.remaining &lt; people_still_needed:\n            msg = (\n                f\"SELECTION IMPOSSIBLE: Not enough people remaining in {feature_name}/{feature_value}. \"\n                f\"Need {people_still_needed} more, but only {fv_counts.remaining} remaining.\"\n            )\n            raise errors.SelectionError(msg)\n\n        # Skip categories with no remaining people or max = 0\n        if fv_counts.remaining == 0 or fv_counts.max == 0:\n            continue\n\n        # Calculate the priority ratio\n        ratio = people_still_needed / float(fv_counts.remaining)\n\n        # Track the highest ratio category\n        if ratio &gt; max_ratio:\n            max_ratio = ratio\n            result_feature_name = feature_name\n            result_feature_value = feature_value\n            # from 1 to remaining\n            random_person_index = random_provider().randbelow(fv_counts.remaining) + 1\n\n    # If no valid category found, all categories must be at their max or have max=0\n    if not result_feature_name:\n        msg = \"No valid categories found - all may be at maximum or have max=0\"\n        raise errors.SelectionError(msg)\n\n    return MaxRatioResult(\n        feature_name=result_feature_name,\n        feature_value=result_feature_value,\n        random_person_index=random_person_index,\n    )\n</code></pre>"},{"location":"modules/#sortition_algorithms.people_features.PeopleFeatures.handle_category_full_deletions","title":"<code>handle_category_full_deletions(selected_person_data)</code>","text":"<p>Check if any categories are now full after a selection and delete remaining people.</p> <p>When a person is selected, some categories may reach their maximum quota. This method identifies such categories and removes all remaining people from them.</p> <p>Parameters:</p> Name Type Description Default <code>selected_person_data</code> <code>dict[str, str]</code> <p>Dictionary of the selected person's feature values</p> required <p>Returns:</p> Type Description <code>list[str]</code> <p>List of output messages about categories that became full and people deleted</p> <p>Raises:</p> Type Description <code>SelectionError</code> <p>If deletions would violate minimum constraints</p> Source code in <code>src/sortition_algorithms/people_features.py</code> <pre><code>def handle_category_full_deletions(self, selected_person_data: dict[str, str]) -&gt; list[str]:\n    \"\"\"\n    Check if any categories are now full after a selection and delete remaining people.\n\n    When a person is selected, some categories may reach their maximum quota.\n    This method identifies such categories and removes all remaining people from them.\n\n    Args:\n        selected_person_data: Dictionary of the selected person's feature values\n\n    Returns:\n        List of output messages about categories that became full and people deleted\n\n    Raises:\n        SelectionError: If deletions would violate minimum constraints\n    \"\"\"\n    output_messages = []\n\n    for (\n        feature_name,\n        feature_value,\n        fv_counts,\n    ) in self.features.feature_values_counts():\n        if feature_value == selected_person_data[feature_name] and fv_counts.selected == fv_counts.max:\n            num_deleted, num_left = self.delete_all_with_feature_value(feature_name, feature_value)\n            if num_deleted &gt; 0:\n                output_messages.append(\n                    f\"Category {feature_name}/{feature_value} full - deleted {num_deleted} people, {num_left} left.\"\n                )\n\n    return output_messages\n</code></pre>"},{"location":"modules/#sortition_algorithms.people_features.PeopleFeatures.prune_for_feature_max_0","title":"<code>prune_for_feature_max_0()</code>","text":"<p>Check if any feature_value.max is set to zero. if so delete everyone with that feature value NOT DONE: could then check if anyone is left.</p> Source code in <code>src/sortition_algorithms/people_features.py</code> <pre><code>def prune_for_feature_max_0(self) -&gt; list[str]:\n    \"\"\"\n    Check if any feature_value.max is set to zero. if so delete everyone with that feature value\n    NOT DONE: could then check if anyone is left.\n    \"\"\"\n    # TODO: when do we want to do this?\n    msg: list[str] = []\n    msg.append(f\"Number of people: {self.people.count}.\")\n    total_num_deleted = 0\n    for (\n        feature_name,\n        feature_value,\n        fv_counts,\n    ) in self.features.feature_values_counts():\n        if fv_counts.max == 0:  # we don't want any of these people\n            # pass the message in as deleting them might throw an exception\n            msg.append(f\"Feature/value {feature_name}/{feature_value} full - deleting people...\")\n            num_deleted, num_left = self.delete_all_with_feature_value(feature_name, feature_value)\n            # if no exception was thrown above add this bit to the end of the previous message\n            msg[-1] += f\" Deleted {num_deleted}, {num_left} left.\"\n            total_num_deleted += num_deleted\n    # if the total number of people deleted is lots then we're probably doing a replacement selection, which means\n    # the 'remaining' file will be useless - remind the user of this!\n    if total_num_deleted &gt;= self.people.count / 2:\n        msg.append(\n            \"&gt;&gt;&gt; WARNING &lt;&lt;&lt; That deleted MANY PEOPLE - are you doing a \"\n            \"replacement? If so your REMAINING FILE WILL BE USELESS!!!\"\n        )\n    return msg\n</code></pre>"},{"location":"modules/#sortition_algorithms.people_features.PeopleFeatures.select_person","title":"<code>select_person(person_key)</code>","text":"<p>Selecting a person means: - remove the person from our copy of People - update the <code>selected</code> and <code>remaining</code> counts of the FeatureCollection - if check_same_address is True, also remove household members (without adding to selected)</p> <p>Returns:</p> Type Description <code>list[str]</code> <p>List of additional people removed due to same address (empty if check_same_address is False)</p> Source code in <code>src/sortition_algorithms/people_features.py</code> <pre><code>def select_person(self, person_key: str) -&gt; list[str]:\n    \"\"\"\n    Selecting a person means:\n    - remove the person from our copy of People\n    - update the `selected` and `remaining` counts of the FeatureCollection\n    - if check_same_address is True, also remove household members (without adding to selected)\n\n    Returns:\n        List of additional people removed due to same address (empty if check_same_address is False)\n    \"\"\"\n    # First, find household members if address checking is enabled (before removing the person)\n    household_members_removed = []\n    if self.check_same_address and self.check_same_address_columns:\n        household_members_removed = list(self.people.matching_address(person_key, self.check_same_address_columns))\n\n    # Handle the main person selection\n    person = self.people.get_person_dict(person_key)\n    for feature in self.features.feature_names:\n        self.features.remove_remaining(feature, person[feature])\n        self.features.add_selected(feature, person[feature])\n    self.people.remove(person_key)\n\n    # Then remove household members if any were found\n    for household_member_key in household_members_removed:\n        household_member = self.people.get_person_dict(household_member_key)\n        for feature in self.features.feature_names:\n            self.features.remove_remaining(feature, household_member[feature])\n            # Note: we don't call add_selected() for household members\n        self.people.remove(household_member_key)\n\n    return household_members_removed\n</code></pre>"},{"location":"modules/#sortition_algorithms.people_features.WeightedSample","title":"<code>WeightedSample</code>","text":"Source code in <code>src/sortition_algorithms/people_features.py</code> <pre><code>class WeightedSample:\n    def __init__(self, features: FeatureCollection) -&gt; None:\n        \"\"\"\n        This produces a set of lists of feature values for each feature.  Each value\n        is in the list `fv_counts.max` times - so a random choice with represent the max.\n\n        So if we had feature \"ethnicity\", value \"white\" w max 4, \"asian\" w max 3 and\n        \"black\" with max 2 we'd get:\n\n        [\"white\", \"white\", \"white\", \"white\", \"asian\", \"asian\", \"asian\", \"black\", \"black\"]\n\n        Then making random choices from that list produces a weighted sample.\n        \"\"\"\n        self.weighted: dict[str, list[str]] = defaultdict(list)\n        for feature_name, value, fv_counts in features.feature_values_counts():\n            self.weighted[feature_name] += [value] * fv_counts.max\n\n    def value_for(self, feature_name: str) -&gt; str:\n        # S311 is random numbers for crypto - but this is just for a sample file\n        return random_provider().choice(self.weighted[feature_name])\n</code></pre>"},{"location":"modules/#sortition_algorithms.people_features.WeightedSample.__init__","title":"<code>__init__(features)</code>","text":"<p>This produces a set of lists of feature values for each feature.  Each value is in the list <code>fv_counts.max</code> times - so a random choice with represent the max.</p> <p>So if we had feature \"ethnicity\", value \"white\" w max 4, \"asian\" w max 3 and \"black\" with max 2 we'd get:</p> <p>[\"white\", \"white\", \"white\", \"white\", \"asian\", \"asian\", \"asian\", \"black\", \"black\"]</p> <p>Then making random choices from that list produces a weighted sample.</p> Source code in <code>src/sortition_algorithms/people_features.py</code> <pre><code>def __init__(self, features: FeatureCollection) -&gt; None:\n    \"\"\"\n    This produces a set of lists of feature values for each feature.  Each value\n    is in the list `fv_counts.max` times - so a random choice with represent the max.\n\n    So if we had feature \"ethnicity\", value \"white\" w max 4, \"asian\" w max 3 and\n    \"black\" with max 2 we'd get:\n\n    [\"white\", \"white\", \"white\", \"white\", \"asian\", \"asian\", \"asian\", \"black\", \"black\"]\n\n    Then making random choices from that list produces a weighted sample.\n    \"\"\"\n    self.weighted: dict[str, list[str]] = defaultdict(list)\n    for feature_name, value, fv_counts in features.feature_values_counts():\n        self.weighted[feature_name] += [value] * fv_counts.max\n</code></pre>"},{"location":"modules/#sortition_algorithms.people_features.simple_add_selected","title":"<code>simple_add_selected(person_keys, people, features)</code>","text":"<p>Just add the person to the selected counts for the feature values for that person. Don't do the more complex handling of the full PeopleFeatures.add_selected()</p> Source code in <code>src/sortition_algorithms/people_features.py</code> <pre><code>def simple_add_selected(person_keys: Iterable[str], people: People, features: FeatureCollection) -&gt; None:\n    \"\"\"\n    Just add the person to the selected counts for the feature values for that person.\n    Don't do the more complex handling of the full PeopleFeatures.add_selected()\n    \"\"\"\n    for person_key in person_keys:\n        person = people.get_person_dict(person_key)\n        for feature_name in features.feature_names:\n            features.add_selected(feature_name, person[feature_name])\n</code></pre>"},{"location":"modules/#sortition_algorithms.people.People","title":"<code>People</code>","text":"Source code in <code>src/sortition_algorithms/people.py</code> <pre><code>class People:\n    def __init__(self, columns_to_keep: list[str]) -&gt; None:\n        self._columns_to_keep = columns_to_keep\n        self._full_data: dict[str, dict[str, str]] = {}\n\n    def __eq__(self, other: Any) -&gt; bool:\n        if not isinstance(other, self.__class__):\n            return False\n        return self._full_data == other._full_data and self._columns_to_keep == self._columns_to_keep\n\n    @property\n    def count(self) -&gt; int:\n        return len(self._full_data)\n\n    def __iter__(self) -&gt; Iterator[str]:\n        return iter(self._full_data)\n\n    def items(self) -&gt; ItemsView[str, dict[str, str]]:\n        return self._full_data.items()\n\n    def add(self, person_key: str, data: StrippedDict, features: FeatureCollection) -&gt; None:\n        person_full_data: dict[str, str] = {}\n        # get the feature values: these are the most important and we must check them\n        for feature_name, feature_values in features.feature_values():\n            # check for input errors here - if it's not in the list of feature values...\n            # allow for some unclean data - at least strip empty space, but only if a str!\n            # (some values will can be numbers)\n            p_value = data[feature_name]\n            if p_value not in feature_values:\n                exc_msg = (\n                    f\"ERROR reading in people (read_in_people): \"\n                    f\"Person (id = {person_key}) has value '{p_value}' not in feature {feature_name}\"\n                )\n                raise errors.BadDataError(exc_msg)\n            person_full_data[feature_name] = p_value\n        # then get the other column values we need\n        # this is address, name etc that we need to keep for output file\n        # we don't check anything here - it's just for user convenience\n        for col in self._columns_to_keep:\n            person_full_data[col] = data[col]\n\n        # add all the data to our people object\n        self._full_data[person_key] = person_full_data\n\n    def remove(self, person_key: str) -&gt; None:\n        del self._full_data[person_key]\n\n    def remove_many(self, person_keys: Iterable[str]) -&gt; None:\n        for key in person_keys:\n            self.remove(key)\n\n    def get_person_dict(self, person_key: str) -&gt; dict[str, str]:\n        return self._full_data[person_key]\n\n    def households(self, address_columns: list[str]) -&gt; dict[tuple[str, ...], list[str]]:\n        \"\"\"\n        Generates a dict with:\n        - keys: a tuple containing the address strings\n        - values: a list of person_key for each person at that address\n        \"\"\"\n        households = defaultdict(list)\n        for person_key, person in self._full_data.items():\n            address = tuple(person[col] for col in address_columns)\n            households[address].append(person_key)\n        return households\n\n    def matching_address(self, person_key: str, address_columns: list[str]) -&gt; Iterable[str]:\n        \"\"\"\n        Returns a list of person keys for all people who have an address matching\n        the address of the person passed in.\n        \"\"\"\n        person = self._full_data[person_key]\n        person_address = tuple(person[col] for col in address_columns)\n        for loop_key, loop_person in self._full_data.items():\n            if loop_key == person_key:\n                continue  # skip the person we've been given\n            if person_address == tuple(loop_person[col] for col in address_columns):\n                yield loop_key\n\n    def find_person_by_position_in_category(self, feature_name: str, feature_value: str, position: int) -&gt; str:\n        \"\"\"\n        Find the nth person (1-indexed) in a specific feature category.\n\n        Args:\n            feature_name: Name of the feature (e.g., \"gender\")\n            feature_value: Value of the feature (e.g., \"male\")\n            position: 1-indexed position within the category\n\n        Returns:\n            Person key of the person at the specified position\n\n        Raises:\n            SelectionError: If no person is found at the specified position\n        \"\"\"\n        current_position = 0\n\n        for person_key, person_dict in self._full_data.items():\n            if person_dict[feature_name] == feature_value:\n                current_position += 1\n                if current_position == position:\n                    return person_key\n\n        # Should always find someone if position is valid\n        msg = f\"Failed to find person at position {position} in {feature_name}/{feature_value}\"\n        raise errors.SelectionError(msg)\n</code></pre>"},{"location":"modules/#sortition_algorithms.people.People.find_person_by_position_in_category","title":"<code>find_person_by_position_in_category(feature_name, feature_value, position)</code>","text":"<p>Find the nth person (1-indexed) in a specific feature category.</p> <p>Parameters:</p> Name Type Description Default <code>feature_name</code> <code>str</code> <p>Name of the feature (e.g., \"gender\")</p> required <code>feature_value</code> <code>str</code> <p>Value of the feature (e.g., \"male\")</p> required <code>position</code> <code>int</code> <p>1-indexed position within the category</p> required <p>Returns:</p> Type Description <code>str</code> <p>Person key of the person at the specified position</p> <p>Raises:</p> Type Description <code>SelectionError</code> <p>If no person is found at the specified position</p> Source code in <code>src/sortition_algorithms/people.py</code> <pre><code>def find_person_by_position_in_category(self, feature_name: str, feature_value: str, position: int) -&gt; str:\n    \"\"\"\n    Find the nth person (1-indexed) in a specific feature category.\n\n    Args:\n        feature_name: Name of the feature (e.g., \"gender\")\n        feature_value: Value of the feature (e.g., \"male\")\n        position: 1-indexed position within the category\n\n    Returns:\n        Person key of the person at the specified position\n\n    Raises:\n        SelectionError: If no person is found at the specified position\n    \"\"\"\n    current_position = 0\n\n    for person_key, person_dict in self._full_data.items():\n        if person_dict[feature_name] == feature_value:\n            current_position += 1\n            if current_position == position:\n                return person_key\n\n    # Should always find someone if position is valid\n    msg = f\"Failed to find person at position {position} in {feature_name}/{feature_value}\"\n    raise errors.SelectionError(msg)\n</code></pre>"},{"location":"modules/#sortition_algorithms.people.People.households","title":"<code>households(address_columns)</code>","text":"<p>Generates a dict with: - keys: a tuple containing the address strings - values: a list of person_key for each person at that address</p> Source code in <code>src/sortition_algorithms/people.py</code> <pre><code>def households(self, address_columns: list[str]) -&gt; dict[tuple[str, ...], list[str]]:\n    \"\"\"\n    Generates a dict with:\n    - keys: a tuple containing the address strings\n    - values: a list of person_key for each person at that address\n    \"\"\"\n    households = defaultdict(list)\n    for person_key, person in self._full_data.items():\n        address = tuple(person[col] for col in address_columns)\n        households[address].append(person_key)\n    return households\n</code></pre>"},{"location":"modules/#sortition_algorithms.people.People.matching_address","title":"<code>matching_address(person_key, address_columns)</code>","text":"<p>Returns a list of person keys for all people who have an address matching the address of the person passed in.</p> Source code in <code>src/sortition_algorithms/people.py</code> <pre><code>def matching_address(self, person_key: str, address_columns: list[str]) -&gt; Iterable[str]:\n    \"\"\"\n    Returns a list of person keys for all people who have an address matching\n    the address of the person passed in.\n    \"\"\"\n    person = self._full_data[person_key]\n    person_address = tuple(person[col] for col in address_columns)\n    for loop_key, loop_person in self._full_data.items():\n        if loop_key == person_key:\n            continue  # skip the person we've been given\n        if person_address == tuple(loop_person[col] for col in address_columns):\n            yield loop_key\n</code></pre>"},{"location":"modules/#sortition_algorithms.utils.RandomProvider","title":"<code>RandomProvider</code>","text":"<p>               Bases: <code>ABC</code></p> <p>This is something of a hack. Mostly we want to use the <code>secrets</code> module. But for repeatable testing we might want to set the random.seed sometimes.</p> <p>So we have a global <code>_random_provider</code> which can be switched between an instance of this class that uses the <code>secrets</code> module and an instance that uses <code>random</code> with a seed. The switch is done by the <code>set_random_provider()</code> function.</p> <p>Then every time we want some randomness, we call <code>random_provider()</code> to get the current version of the global.</p> Source code in <code>src/sortition_algorithms/utils.py</code> <pre><code>class RandomProvider(ABC):\n    \"\"\"\n    This is something of a hack. Mostly we want to use the `secrets` module.\n    But for repeatable testing we might want to set the random.seed sometimes.\n\n    So we have a global `_random_provider` which can be switched between an\n    instance of this class that uses the `secrets` module and an instance that\n    uses `random` with a seed. The switch is done by the `set_random_provider()`\n    function.\n\n    Then every time we want some randomness, we call `random_provider()` to get\n    the current version of the global.\n    \"\"\"\n\n    @classmethod\n    @abstractmethod\n    def uniform(cls, lower: float, upper: float) -&gt; float: ...\n\n    @classmethod\n    @abstractmethod\n    def randbelow(cls, upper: int) -&gt; int: ...\n\n    @classmethod\n    @abstractmethod\n    def choice(cls, seq: \"SupportsLenAndGetItem[str]\") -&gt; str: ...\n</code></pre>"},{"location":"modules/#sortition_algorithms.utils.StrippedDict","title":"<code>StrippedDict</code>","text":"<p>Wraps a dict, and whenever we get a value from it, we convert to str and strip() whitespace</p> Source code in <code>src/sortition_algorithms/utils.py</code> <pre><code>class StrippedDict:\n    \"\"\"\n    Wraps a dict, and whenever we get a value from it, we convert to str and\n    strip() whitespace\n    \"\"\"\n\n    def __init__(self, raw_dict: Mapping[str, str] | Mapping[str, str | int]) -&gt; None:\n        self.raw_dict = raw_dict\n\n    def __getitem__(self, key: str) -&gt; str:\n        return strip_str_int(self.raw_dict[key])\n</code></pre>"},{"location":"modules/#sortition_algorithms.utils.print_ret","title":"<code>print_ret(message)</code>","text":"<p>Print and return a message for output collection.</p> Source code in <code>src/sortition_algorithms/utils.py</code> <pre><code>def print_ret(message: str) -&gt; str:\n    \"\"\"Print and return a message for output collection.\"\"\"\n    # TODO: should we replace this with logging or similar?\n    print(message)\n    return message\n</code></pre>"},{"location":"quickstart/","title":"Quick Start Guide","text":"<p>This guide will get you up and running with sortition algorithms in just a few minutes.</p>"},{"location":"quickstart/#installation","title":"Installation","text":"<pre><code>pip install sortition-algorithms\n\n# Optional: Install CLI support\npip install 'sortition-algorithms[cli]'\n\n# Optional: Install leximin algorithm support (requires commercial/academic license)\npip install 'sortition-algorithms[gurobi]'\n</code></pre>"},{"location":"quickstart/#basic-concepts","title":"Basic Concepts","text":"<p>Before diving in, understand these key concepts:</p> <ul> <li>Sortition: Random selection that maintains demographic representativeness</li> <li>Features: Demographic characteristics (e.g., Gender, Age, Location)</li> <li>Quotas: Min/max targets for each demographic group</li> <li>Stratified Selection: Random selection that respects quotas</li> </ul>"},{"location":"quickstart/#your-first-selection","title":"Your First Selection","text":""},{"location":"quickstart/#1-prepare-your-data","title":"1. Prepare Your Data","text":"<p>You'll need two CSV files:</p> <p>demographics.csv (features with quotas):</p> <pre><code>feature,value,min,max\nGender,Male,45,55\nGender,Female,45,55\nAge,18-30,20,30\nAge,31-50,30,40\nAge,51+,30,50\n</code></pre> <p>candidates.csv (people to select from):</p> <pre><code>id,Gender,Age,Location\nperson1,Male,18-30,Urban\nperson2,Female,31-50,Rural\nperson3,Male,51+,Urban\n...\n</code></pre>"},{"location":"quickstart/#2-run-your-first-selection","title":"2. Run Your First Selection","text":"<pre><code>from sortition_algorithms import (\n    run_stratification,\n    read_in_features,\n    read_in_people,\n    Settings\n)\n\n# Load your data\nsettings = Settings()\nfeatures = read_in_features(\"demographics.csv\")\npeople = read_in_people(\"candidates.csv\", settings, features)\n\n# Select a panel of 50 people\nsuccess, selected_panels, messages = run_stratification(\n    features=features,\n    people=people,\n    number_people_wanted=50,\n    settings=settings\n)\n\nif success:\n    selected_people = selected_panels[0]  # frozenset of person IDs\n    print(f\"\u2705 Successfully selected {len(selected_people)} people\")\n    print(\"Selected IDs:\", list(selected_people)[:5], \"...\")\nelse:\n    print(\"\u274c Selection failed\")\n    for msg in messages:\n        print(msg)\n</code></pre>"},{"location":"quickstart/#3-export-results","title":"3. Export Results","text":"<pre><code>from sortition_algorithms import selected_remaining_tables\n\n# Get formatted tables for export\nselected_table, remaining_table, info = selected_remaining_tables(\n    people, selected_panels[0], features, settings\n)\n\n# Save to CSV\nimport csv\n\nwith open(\"selected.csv\", \"w\", newline=\"\") as f:\n    writer = csv.writer(f)\n    writer.writerows(selected_table)\n\nwith open(\"remaining.csv\", \"w\", newline=\"\") as f:\n    writer = csv.writer(f)\n    writer.writerows(remaining_table)\n</code></pre>"},{"location":"quickstart/#using-the-command-line","title":"Using the Command Line","text":"<p>For quick operations, use the CLI:</p> <pre><code># CSV workflow\npython -m sortition_algorithms csv \\\n  --settings settings.toml \\\n  --features-csv demographics.csv \\\n  --people-csv candidates.csv \\\n  --selected-csv selected.csv \\\n  --remaining-csv remaining.csv \\\n  --number-wanted 50\n</code></pre>"},{"location":"quickstart/#configuration-with-settings","title":"Configuration with Settings","text":"<p>Customize behavior with a settings file:</p> <p>settings.toml:</p> <pre><code># Random seed for reproducible results (optional)\nrandom_number_seed = 42\n\n# Ensure household diversity\ncheck_same_address = true\ncheck_same_address_columns = [\"Address\", \"Postcode\"]\n\n# Selection algorithm: \"maximin\", \"leximin\", \"nash\", or \"legacy\"\nselection_algorithm = \"maximin\"\n\n# Maximum selection attempts\nmax_attempts = 10\n\n# Output columns to include\ncolumns_to_keep = [\"Name\", \"Email\", \"Phone\"]\n</code></pre> <pre><code>settings = Settings.load_from_file(\"settings.toml\")\n</code></pre>"},{"location":"quickstart/#common-patterns","title":"Common Patterns","text":""},{"location":"quickstart/#working-with-google-sheets","title":"Working with Google Sheets","text":"<pre><code>from sortition_algorithms import GSheetAdapter\nfrom pathlib import Path\n\nadapter = GSheetAdapter(Path(\"credentials.json\"))\nfeatures, msgs = adapter.load_features(\"My Spreadsheet\", \"Demographics\")\npeople, msgs = adapter.load_people(\"Candidates\", settings, features)\n</code></pre>"},{"location":"quickstart/#address-checking-for-household-diversity","title":"Address Checking for Household Diversity","text":"<pre><code># Ensure only one person per household is selected\nsettings = Settings(\n    check_same_address=True,\n    check_same_address_columns=[\"Address\", \"Postcode\"]\n)\n</code></pre>"},{"location":"quickstart/#multiple-selection-algorithms","title":"Multiple Selection Algorithms","text":"<pre><code># Maximin: Maximize the minimum probability\nsettings.selection_algorithm = \"maximin\"\n\n# Nash: Maximize the product of probabilities\nsettings.selection_algorithm = \"nash\"\n\n# Leximin: Lexicographic maximin (requires Gurobi)\nsettings.selection_algorithm = \"leximin\"\n</code></pre>"},{"location":"quickstart/#whats-next","title":"What's Next?","text":"<ul> <li>Core Concepts - Deep dive into sortition theory</li> <li>API Reference - Complete function documentation</li> <li>CLI Usage - Advanced command line examples</li> <li>Data Adapters - CSV, Google Sheets, and custom adapters</li> <li>Advanced Usage - Complex scenarios and troubleshooting</li> </ul>"},{"location":"quickstart/#troubleshooting","title":"Troubleshooting","text":"<p>\"Selection failed\" errors: Check that your quotas are achievable given your candidate pool. The sum of minimum quotas shouldn't exceed your target panel size.</p> <p>Import errors: Ensure you've installed the package correctly. For Gurobi features, you need a valid license.</p> <p>Empty results: Verify your CSV files have the correct format and column names match between demographics and candidates files.</p>"}]}